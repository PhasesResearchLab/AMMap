{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building Compositional Space Complexes to Express Elaborate Design Problems\n",
    "\n",
    "> ***(before running this code, please consult Quick Start to make sure everything is set up)***\n",
    "\n",
    "> You will need the same dependencies as in [Tutorial No.2](02.AdditiveManufacturingPathPlanning.ipynb) (i.e., `pycalphad` and `pathfinding`), and additionally `igraph` in order to efficiently visualize the examples presented in this tutorial. **If you are running this in `nimplex`'s Codespaces, everything has been pre-installed for you.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this tutorial, we will build upon `nimplex`'s graph representations and leverage our ability to combine (\"stitch\") them together without affecting the way we express the problem at hand and in an effortless fashion to dramatically speed up materials exploration.** In particular, we will show how to:\n",
    "\n",
    "1. **Plot graphs** (as in mathematical objects, not any figures) using [`igraph`](https://igraph.org/), which can be done quite directly using `nimplex`'s point grid and neighbor lists `edges = [(i,n) for i in range(len(gridAtt)) for n in nList[i]]`\n",
    "\n",
    "2. **Identify ordered subsystems in `nimplex` grids, like `A-B-C` and `C-A-B` within `A-B-C-D-E` and `D-C-G-F-A-H-B` to establish connectivity between them.** We will use this to combine 3 4-component systems (tetrahedra) by 2 3-component subsystems (triangles) to create a chain.\n",
    "\n",
    "3. Identify all subspaces of a given order in low dimensional and high dimensional spaces (e.g., all quantized compositions of any 3 things out of N) and combine (\"stitch\") them together to form a **simplex graphs that intersect themselves in 3D because of high dimensionality, yet still have the same (graph) structure**.\n",
    "\n",
    "4. **Construct a graph complex to explore all ternary combinations of `[\"Ti50Zr50\", \"Hf95Ti5\", \"NbTaWHf\", \"Mo80Nb10W10\", \"TiTa2\", \"Nb96Mo3W1\", \"Zr49 Hf1 Mo50\"]` (7 alloys)** under equilibrium phase constraint (relatively expensive to compute) and then explore the space with an additional low-cost screenig constraint (RMSAD - alloy strenght surrogate) that could also be an ML surrogate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nimplex\n",
    "from utils import stitching\n",
    "from IPython.display import clear_output\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting 4-Component Simplex Graph with `igraph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 4\n",
    "ndiv = 6\n",
    "gridAtt, nList = nimplex.simplex_graph_py(dim, ndiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for i in range(len(gridAtt)):\n",
    "    for n in nList[i]:\n",
    "        edges.append((i,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph(edges: list):\n",
    "    # Lets generate some seed positions for the nodes\n",
    "    G = ig.Graph(edges)\n",
    "    layout = G.layout_kamada_kawai(dim=3)\n",
    "    layout_array = np.array(layout.coords)\n",
    "    # Create edge traces\n",
    "    edge_traces = []\n",
    "    for edge in G.es:\n",
    "        start, end = edge.tuple\n",
    "        x0, y0, z0 = layout_array[start]\n",
    "        x1, y1, z1 = layout_array[end]\n",
    "        width = 5\n",
    "        edge_trace = go.Scatter3d(x=[x0, x1], y=[y0, y1], z=[z0, z1],\n",
    "                                line=dict(width=width, color='lightgray'),\n",
    "                                opacity=0.2,\n",
    "                                hoverinfo='none', mode='lines')\n",
    "        edge_traces.append(edge_trace)\n",
    "\n",
    "    node_trace = go.Scatter3d(x=layout_array[:, 0], y=layout_array[:, 1], z=layout_array[:, 2],\n",
    "                            mode='markers',\n",
    "                            marker=dict(size=3, \n",
    "                                        opacity=0.5,\n",
    "                                        line=None,\n",
    "                                        color='blue'),\n",
    "                            \n",
    "                            text=[f\"Node {i}\" for i in range(len(gridAtt))],\n",
    "                            hoverinfo='text')\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=edge_traces + [node_trace])\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='3D Graph with Feasibility Types',\n",
    "        scene=dict(\n",
    "            xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False),\n",
    "            zaxis=dict(visible=False),\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        margin=dict(l=0, r=0, b=0, t=0),\n",
    "        width=800\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGraph(edges)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining (\"Stitching\") 3 4-Component Systems into A Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys1 = [\"A\", \"B\", \"C\", \"D\"]\n",
    "sys2 = [\"B\", \"C\", \"D\", \"E\"]\n",
    "sys3 = [\"B\", \"D\", \"E\", \"F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = len(gridAtt)\n",
    "for i in range(len(gridAtt)):\n",
    "    for n in nList[i]:\n",
    "        edges.append((i+offset,n+offset))\n",
    "for i in range(len(gridAtt)):\n",
    "    for n in nList[i]:\n",
    "        edges.append((i+offset*2,n+offset*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGraph(edges)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 82, 79, 73, 63, 48, 27]\n"
     ]
    }
   ],
   "source": [
    "stitchingPoints = stitching.findStitchingPoints_py(dim, ndiv, components=[\"A\", \"B\", \"C\", \"D\"])\n",
    "print(stitchingPoints[\"A-B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchingPoints1 = stitching.findStitchingPoints_py(dim, ndiv, components=sys1, offset=0)\n",
    "stitchingPoints2 = stitching.findStitchingPoints_py(dim, ndiv, components=sys2, offset=len(gridAtt))\n",
    "stitchingPoints3 = stitching.findStitchingPoints_py(dim, ndiv, components=sys3, offset=len(gridAtt)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(stitchingPoints1[\"B-C-D\"], stitchingPoints2[\"B-C-D\"]):\n",
    "    edges.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(stitchingPoints2[\"B-D-E\"], stitchingPoints3[\"B-D-E\"]):\n",
    "    edges.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGraph(edges)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining (\"Stitching\") 9 3-Component Systems into A Complex\n",
    "### Disregard this section for now Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 3\n",
    "ndiv = 6\n",
    "nsys = 9\n",
    "gridAtt, nList = nimplex.simplex_graph_py(dim, ndiv)\n",
    "edges = []\n",
    "for i in range(len(gridAtt)):\n",
    "    for n in nList[i]:\n",
    "        edges.append((i,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gridAtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = len(gridAtt)\n",
    "for sys in range(1,nsys+1):\n",
    "    for i in range(len(gridAtt)):\n",
    "        for n in nList[i]:\n",
    "            edges.append((i+offset*sys,n+offset*sys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGraph(edges)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycalphad import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ocean/projects/dmr190011p/arichte1/micromamba/envs/v2ammap/lib/python3.11/site-packages/pycalphad/io/tdb.py:293: UserWarning: The type definition character `&` in `TYPE_DEFINITION & GES A_P_D A2_BCC MAGNETIC -1.0 4.00000E-01 ` is not used by any phase.\n",
      "  warnings.warn(f\"The type definition character `{typechar}` in `TYPE_DEFINITION {typechar} {line}` is not used by any phase.\")\n"
     ]
    }
   ],
   "source": [
    "dbCrNiV = Database(\"ammap/databases/Co-Cr-Fe-Ni-V_choi2019.TDB\")\n",
    "dbCrFeTi = Database(\"ammap/databases/Cr-Fe-Ti_wang2017.tdb\")\n",
    "dbCrFeNi = Database(\"ammap/databases/Cr-Fe-Ni_miettinen1999.tdb\")\n",
    "dbCrNiTi= Database(\"ammap/databases/Cr-Ni-Ti_huang2018.tdb\")\n",
    "dbCrTiV= Database(\"ammap/databases/Cr-Ti-V_ghosh2002.tdb\")\n",
    "dbFeNiTi= Database(\"ammap/databases/Fe-Ni-Ti_dekeyzer2009.tdb\")\n",
    "dbFeNiV= Database(\"ammap/databases/Fe-Ni-V_zhao2014.tdb\")\n",
    "dbFeTiV= Database(\"ammap/databases/Fe-Ti-V_guo2012.TDB\")\n",
    "dbNiTiV= Database(\"ammap/databases/Ni-Ti-V_zou2018.tdb\")\n",
    "CrNiV = ['Cr', 'Ni', 'V']\n",
    "CrFeTi = ['Cr', 'Fe', 'Ti']\n",
    "CrFeNi = ['Cr', 'Fe', 'Ni']\n",
    "CrNiTi = ['Cr', 'Ni', 'Ti']\n",
    "CrTiV = ['Cr', 'Ti', 'V']\n",
    "FeNiTi = ['Fe', 'Ni', 'Ti']\n",
    "FeNiV = ['Fe', 'Ni', 'V']\n",
    "FeTiV = ['Fe', 'Ti', 'V']\n",
    "NiTiV = ['Ni', 'Ti', 'V']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchingPointsCrNiV = stitching.findStitchingPoints_py(dim, ndiv, components=CrNiV, offset=0)\n",
    "stitchingPointsCrFeTi = stitching.findStitchingPoints_py(dim, ndiv, components=CrFeTi, offset=len(gridAtt))\n",
    "stitchingPointsCrFeNi = stitching.findStitchingPoints_py(dim, ndiv, components=CrFeNi, offset=len(gridAtt)*2)\n",
    "stitchingPointsCrNiTi = stitching.findStitchingPoints_py(dim, ndiv, components=CrNiTi, offset=len(gridAtt)*3)\n",
    "stitchingPointsCrTiV = stitching.findStitchingPoints_py(dim, ndiv, components=CrTiV, offset=len(gridAtt)*4)\n",
    "stitchingPointsFeNiTi = stitching.findStitchingPoints_py(dim, ndiv, components=FeNiTi, offset=len(gridAtt)*5)\n",
    "stitchingPointsFeNiV = stitching.findStitchingPoints_py(dim, ndiv, components=FeNiV, offset=len(gridAtt)*6)\n",
    "stitchingPointsFeTiV = stitching.findStitchingPoints_py(dim, ndiv, components=FeTiV, offset=len(gridAtt)*7)\n",
    "stitchingPointsNiTiV = stitching.findStitchingPoints_py(dim, ndiv, components=NiTiV, offset=len(gridAtt)*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding and Combining 3-Component Subspaces in 4-Component Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'B', 'C'), ('A', 'B', 'D'), ('A', 'C', 'D'), ('B', 'C', 'D')]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "elements = [\"A\", \"B\", \"C\", \"D\"]\n",
    "ternaries = list(combinations(elements, 3))\n",
    "print(ternaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridAtt, nList = nimplex.simplex_graph_py(3,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "# Ternaries\n",
    "for i, ternary in enumerate(ternaries):\n",
    "    offset = i*len(gridAtt)\n",
    "    for i in range(len(gridAtt)):\n",
    "        for n in nList[i]:\n",
    "            edges.append((i+offset,n+offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGraph(edges)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 'B'): occurs between ternary [(0, 1)]\n",
      "('A', 'C'): occurs between ternary [(0, 2)]\n",
      "('B', 'C'): occurs between ternary [(0, 3)]\n",
      "('A', 'D'): occurs between ternary [(1, 2)]\n",
      "('B', 'D'): occurs between ternary [(1, 3)]\n",
      "('C', 'D'): occurs between ternary [(2, 3)]\n"
     ]
    }
   ],
   "source": [
    "stitchingBinaries = {}\n",
    "\n",
    "for i, combo1 in enumerate(ternaries):\n",
    "    for j, combo2 in enumerate(ternaries[i+1:], start=i+1):\n",
    "        common = set(combo1) & set(combo2)\n",
    "        if len(common) == 2:\n",
    "            overlap = tuple(sorted(common))\n",
    "            if overlap not in stitchingBinaries:\n",
    "                stitchingBinaries[overlap] = []\n",
    "            stitchingBinaries[overlap].append((i, j))\n",
    "\n",
    "for overlap, pairs in stitchingBinaries.items():\n",
    "    print(f\"{overlap}: occurs between ternary {pairs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching 0 and 1 at ('A', 'B') from [90, 89, 87, 84, 80, 75, 69, 62, 54, 45, 35, 24, 12] to [181, 180, 178, 175, 171, 166, 160, 153, 145, 136, 126, 115, 103]\n",
      "Stitching 0 and 2 at ('A', 'C') from [90, 88, 85, 81, 76, 70, 63, 55, 46, 36, 25, 13, 0] to [272, 271, 269, 266, 262, 257, 251, 244, 236, 227, 217, 206, 194]\n",
      "Stitching 0 and 3 at ('B', 'C') from [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0] to [363, 362, 360, 357, 353, 348, 342, 335, 327, 318, 308, 297, 285]\n",
      "Stitching 1 and 2 at ('A', 'D') from [181, 179, 176, 172, 167, 161, 154, 146, 137, 127, 116, 104, 91] to [272, 270, 267, 263, 258, 252, 245, 237, 228, 218, 207, 195, 182]\n",
      "Stitching 1 and 3 at ('B', 'D') from [103, 102, 101, 100, 99, 98, 97, 96, 95, 94, 93, 92, 91] to [363, 361, 358, 354, 349, 343, 336, 328, 319, 309, 298, 286, 273]\n",
      "Stitching 2 and 3 at ('C', 'D') from [194, 193, 192, 191, 190, 189, 188, 187, 186, 185, 184, 183, 182] to [285, 284, 283, 282, 281, 280, 279, 278, 277, 276, 275, 274, 273]\n"
     ]
    }
   ],
   "source": [
    "for stitchingBinary, ternaryPair in stitchingBinaries.items():\n",
    "    ternary1, ternary2 = ternaryPair[0][0], ternaryPair[0][1]\n",
    "    stitching1 = stitching.findStitchingPoints_py(\n",
    "        3, 12, \n",
    "        components=ternaries[ternary1],\n",
    "        offset=ternary1*len(gridAtt)\n",
    "        )[\"-\".join(stitchingBinary)]\n",
    "    stitching2 = stitching.findStitchingPoints_py(\n",
    "        3, 12, \n",
    "        components=ternaries[ternary2],\n",
    "        offset=ternary2*len(gridAtt)\n",
    "        )[\"-\".join(stitchingBinary)]\n",
    "    print(f\"Stitching {ternary1} and {ternary2} at {stitchingBinary} from {stitching1} to {stitching2}\")\n",
    "    for i, j in zip(stitching1, stitching2):\n",
    "        edges.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGraph(edges)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Higher Dimensional Cases (Stretched 2D Spaces Crossing Each Other in 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'B', 'C'), ('A', 'B', 'D'), ('A', 'B', 'E'), ('A', 'C', 'D'), ('A', 'C', 'E'), ('A', 'D', 'E'), ('B', 'C', 'D'), ('B', 'C', 'E'), ('B', 'D', 'E'), ('C', 'D', 'E')]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "elements = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "ternaries = list(combinations(elements, 3))\n",
    "print(ternaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridAtt, nList = nimplex.simplex_graph_py(3,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "# Ternaries\n",
    "for i, ternary in enumerate(ternaries):\n",
    "    offset = i*len(gridAtt)\n",
    "    for i in range(len(gridAtt)):\n",
    "        for n in nList[i]:\n",
    "            edges.append((i+offset,n+offset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGraph(edges)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 'B'): occurs between ternary [(0, 1), (0, 2), (1, 2)]\n",
      "('A', 'C'): occurs between ternary [(0, 3), (0, 4), (3, 4)]\n",
      "('B', 'C'): occurs between ternary [(0, 6), (0, 7), (6, 7)]\n",
      "('A', 'D'): occurs between ternary [(1, 3), (1, 5), (3, 5)]\n",
      "('B', 'D'): occurs between ternary [(1, 6), (1, 8), (6, 8)]\n",
      "('A', 'E'): occurs between ternary [(2, 4), (2, 5), (4, 5)]\n",
      "('B', 'E'): occurs between ternary [(2, 7), (2, 8), (7, 8)]\n",
      "('C', 'D'): occurs between ternary [(3, 6), (3, 9), (6, 9)]\n",
      "('C', 'E'): occurs between ternary [(4, 7), (4, 9), (7, 9)]\n",
      "('D', 'E'): occurs between ternary [(5, 8), (5, 9), (8, 9)]\n"
     ]
    }
   ],
   "source": [
    "stitchingBinaries = {}\n",
    "\n",
    "for i, combo1 in enumerate(ternaries):\n",
    "    for j, combo2 in enumerate(ternaries[i+1:], start=i+1):\n",
    "        common = set(combo1) & set(combo2)\n",
    "        if len(common) == 2:\n",
    "            overlap = tuple(sorted(common))\n",
    "            if overlap not in stitchingBinaries:\n",
    "                stitchingBinaries[overlap] = []\n",
    "            stitchingBinaries[overlap].append((i, j))\n",
    "\n",
    "for overlap, pairs in stitchingBinaries.items():\n",
    "    print(f\"{overlap}: occurs between ternary {pairs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching 0 and 1 at ('A', 'B') from [90, 89, 87, 84, 80, 75, 69, 62, 54, 45, 35, 24, 12] to [181, 180, 178, 175, 171, 166, 160, 153, 145, 136, 126, 115, 103]\n",
      "Stitching 0 and 2 at ('A', 'B') from [90, 89, 87, 84, 80, 75, 69, 62, 54, 45, 35, 24, 12] to [272, 271, 269, 266, 262, 257, 251, 244, 236, 227, 217, 206, 194]\n",
      "Stitching 1 and 2 at ('A', 'B') from [181, 180, 178, 175, 171, 166, 160, 153, 145, 136, 126, 115, 103] to [272, 271, 269, 266, 262, 257, 251, 244, 236, 227, 217, 206, 194]\n",
      "Stitching 0 and 3 at ('A', 'C') from [90, 88, 85, 81, 76, 70, 63, 55, 46, 36, 25, 13, 0] to [363, 362, 360, 357, 353, 348, 342, 335, 327, 318, 308, 297, 285]\n",
      "Stitching 0 and 4 at ('A', 'C') from [90, 88, 85, 81, 76, 70, 63, 55, 46, 36, 25, 13, 0] to [454, 453, 451, 448, 444, 439, 433, 426, 418, 409, 399, 388, 376]\n",
      "Stitching 3 and 4 at ('A', 'C') from [363, 362, 360, 357, 353, 348, 342, 335, 327, 318, 308, 297, 285] to [454, 453, 451, 448, 444, 439, 433, 426, 418, 409, 399, 388, 376]\n",
      "Stitching 0 and 6 at ('B', 'C') from [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0] to [636, 635, 633, 630, 626, 621, 615, 608, 600, 591, 581, 570, 558]\n",
      "Stitching 0 and 7 at ('B', 'C') from [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0] to [727, 726, 724, 721, 717, 712, 706, 699, 691, 682, 672, 661, 649]\n",
      "Stitching 6 and 7 at ('B', 'C') from [636, 635, 633, 630, 626, 621, 615, 608, 600, 591, 581, 570, 558] to [727, 726, 724, 721, 717, 712, 706, 699, 691, 682, 672, 661, 649]\n",
      "Stitching 1 and 3 at ('A', 'D') from [181, 179, 176, 172, 167, 161, 154, 146, 137, 127, 116, 104, 91] to [363, 361, 358, 354, 349, 343, 336, 328, 319, 309, 298, 286, 273]\n",
      "Stitching 1 and 5 at ('A', 'D') from [181, 179, 176, 172, 167, 161, 154, 146, 137, 127, 116, 104, 91] to [545, 544, 542, 539, 535, 530, 524, 517, 509, 500, 490, 479, 467]\n",
      "Stitching 3 and 5 at ('A', 'D') from [363, 361, 358, 354, 349, 343, 336, 328, 319, 309, 298, 286, 273] to [545, 544, 542, 539, 535, 530, 524, 517, 509, 500, 490, 479, 467]\n",
      "Stitching 1 and 6 at ('B', 'D') from [103, 102, 101, 100, 99, 98, 97, 96, 95, 94, 93, 92, 91] to [636, 634, 631, 627, 622, 616, 609, 601, 592, 582, 571, 559, 546]\n",
      "Stitching 1 and 8 at ('B', 'D') from [103, 102, 101, 100, 99, 98, 97, 96, 95, 94, 93, 92, 91] to [818, 817, 815, 812, 808, 803, 797, 790, 782, 773, 763, 752, 740]\n",
      "Stitching 6 and 8 at ('B', 'D') from [636, 634, 631, 627, 622, 616, 609, 601, 592, 582, 571, 559, 546] to [818, 817, 815, 812, 808, 803, 797, 790, 782, 773, 763, 752, 740]\n",
      "Stitching 2 and 4 at ('A', 'E') from [272, 270, 267, 263, 258, 252, 245, 237, 228, 218, 207, 195, 182] to [454, 452, 449, 445, 440, 434, 427, 419, 410, 400, 389, 377, 364]\n",
      "Stitching 2 and 5 at ('A', 'E') from [272, 270, 267, 263, 258, 252, 245, 237, 228, 218, 207, 195, 182] to [545, 543, 540, 536, 531, 525, 518, 510, 501, 491, 480, 468, 455]\n",
      "Stitching 4 and 5 at ('A', 'E') from [454, 452, 449, 445, 440, 434, 427, 419, 410, 400, 389, 377, 364] to [545, 543, 540, 536, 531, 525, 518, 510, 501, 491, 480, 468, 455]\n",
      "Stitching 2 and 7 at ('B', 'E') from [194, 193, 192, 191, 190, 189, 188, 187, 186, 185, 184, 183, 182] to [727, 725, 722, 718, 713, 707, 700, 692, 683, 673, 662, 650, 637]\n",
      "Stitching 2 and 8 at ('B', 'E') from [194, 193, 192, 191, 190, 189, 188, 187, 186, 185, 184, 183, 182] to [818, 816, 813, 809, 804, 798, 791, 783, 774, 764, 753, 741, 728]\n",
      "Stitching 7 and 8 at ('B', 'E') from [727, 725, 722, 718, 713, 707, 700, 692, 683, 673, 662, 650, 637] to [818, 816, 813, 809, 804, 798, 791, 783, 774, 764, 753, 741, 728]\n",
      "Stitching 3 and 6 at ('C', 'D') from [285, 284, 283, 282, 281, 280, 279, 278, 277, 276, 275, 274, 273] to [558, 557, 556, 555, 554, 553, 552, 551, 550, 549, 548, 547, 546]\n",
      "Stitching 3 and 9 at ('C', 'D') from [285, 284, 283, 282, 281, 280, 279, 278, 277, 276, 275, 274, 273] to [909, 908, 906, 903, 899, 894, 888, 881, 873, 864, 854, 843, 831]\n",
      "Stitching 6 and 9 at ('C', 'D') from [558, 557, 556, 555, 554, 553, 552, 551, 550, 549, 548, 547, 546] to [909, 908, 906, 903, 899, 894, 888, 881, 873, 864, 854, 843, 831]\n",
      "Stitching 4 and 7 at ('C', 'E') from [376, 375, 374, 373, 372, 371, 370, 369, 368, 367, 366, 365, 364] to [649, 648, 647, 646, 645, 644, 643, 642, 641, 640, 639, 638, 637]\n",
      "Stitching 4 and 9 at ('C', 'E') from [376, 375, 374, 373, 372, 371, 370, 369, 368, 367, 366, 365, 364] to [909, 907, 904, 900, 895, 889, 882, 874, 865, 855, 844, 832, 819]\n",
      "Stitching 7 and 9 at ('C', 'E') from [649, 648, 647, 646, 645, 644, 643, 642, 641, 640, 639, 638, 637] to [909, 907, 904, 900, 895, 889, 882, 874, 865, 855, 844, 832, 819]\n",
      "Stitching 5 and 8 at ('D', 'E') from [467, 466, 465, 464, 463, 462, 461, 460, 459, 458, 457, 456, 455] to [740, 739, 738, 737, 736, 735, 734, 733, 732, 731, 730, 729, 728]\n",
      "Stitching 5 and 9 at ('D', 'E') from [467, 466, 465, 464, 463, 462, 461, 460, 459, 458, 457, 456, 455] to [831, 830, 829, 828, 827, 826, 825, 824, 823, 822, 821, 820, 819]\n",
      "Stitching 8 and 9 at ('D', 'E') from [740, 739, 738, 737, 736, 735, 734, 733, 732, 731, 730, 729, 728] to [831, 830, 829, 828, 827, 826, 825, 824, 823, 822, 821, 820, 819]\n"
     ]
    }
   ],
   "source": [
    "for stitchingBinary, ternaryPairList in stitchingBinaries.items():\n",
    "    for ternaryPair in ternaryPairList:\n",
    "        ternary1, ternary2 = ternaryPair[0], ternaryPair[1]\n",
    "        stitching1 = stitching.findStitchingPoints_py(\n",
    "            3, 12, \n",
    "            components=ternaries[ternary1],\n",
    "            offset=ternary1*len(gridAtt)\n",
    "            )[\"-\".join(stitchingBinary)]\n",
    "        stitching2 = stitching.findStitchingPoints_py(\n",
    "            3, 12, \n",
    "            components=ternaries[ternary2],\n",
    "            offset=ternary2*len(gridAtt)\n",
    "            )[\"-\".join(stitchingBinary)]\n",
    "        print(f\"Stitching {ternary1} and {ternary2} at {stitchingBinary} from {stitching1} to {stitching2}\")\n",
    "        for i, j in zip(stitching1, stitching2):\n",
    "            edges.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotGraph(edges)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Complex Formed by All 3-Component Alloy Subsystems of 5-Component Space (w. Infeasibility Gliding) #THIS ONE ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cr', 'Fe', 'Ni')                       -> ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0])\n",
      "('Cr', 'Fe', 'Ti')                       -> ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0])\n",
      "('Cr', 'Fe', 'V')                        -> ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 1])\n",
      "('Cr', 'Ni', 'Ti')                       -> ([1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0])\n",
      "('Cr', 'Ni', 'V')                        -> ([1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1])\n",
      "('Cr', 'Ti', 'V')                        -> ([1, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n",
      "('Fe', 'Ni', 'Ti')                       -> ([0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0])\n",
      "('Fe', 'Ni', 'V')                        -> ([0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1])\n",
      "('Fe', 'Ti', 'V')                        -> ([0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n",
      "('Ni', 'Ti', 'V')                        -> ([0, 0, 1, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "elementalSpaceComponents = [\"Cr\",\"Fe\",\"Ni\",\"Ti\",\"V\"]\n",
    "#attainableSpaceComponents = [\"SS304L\", \"Ni\", \"Cr\", \"V\", \"Ti\"]\n",
    "attainableSpaceComponents = [\"Cr\", \"Fe\", \"Ni\", \"Ti\", \"V\"]\n",
    "attainableSpaceComponentPositions = [\n",
    "    #\"Cr\",\"Fe\",\"Ni\",\"Ti\",\"V\"\n",
    "    #[0.1993865031, 0.7044989775,0.096114519430,0,0],\n",
    "    [1,0,0,0,0],\n",
    "    [0,1,0,0,0],\n",
    "    [0,0,1,0,0],\n",
    "    [0,0,0,1,0],\n",
    "    [0,0,0,0,1]\n",
    "]    \n",
    "ternaries = list(combinations(attainableSpaceComponents, 3))\n",
    "ternaries_CompPos = list(combinations(attainableSpaceComponentPositions, 3))\n",
    "ndiv = 32\n",
    "#ndiv = 5\n",
    "gridAtt, nList = nimplex.simplex_graph_py(3, ndiv)\n",
    "\n",
    "for tern, terncp in zip(ternaries, ternaries_CompPos):\n",
    "    print(f\"{str(tern):<40} -> {terncp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges list for graph plotting and path finding purposes\n",
    "edges = []\n",
    "# Connectivity list within each subsystem\n",
    "graphN = [[] for i in range(len(gridAtt * len(ternaries)))]\n",
    "# Connectivity list between subsystems\n",
    "graphNS = [[] for i in range(len(graphN))]\n",
    "compositions = []\n",
    "compositions_with_id = []  # List to store compositions with their identifiers\n",
    "ternaries_with_id = []  # New list to store ternaries_CompPos with their identifiers\n",
    "\n",
    "# Iterate over ternaries\n",
    "for i, terncp in enumerate(ternaries_CompPos):\n",
    "    ternaries_with_id.append((terncp, i))  # Add terncp and its id to the new list\n",
    "    \n",
    "    offset = i*len(gridAtt)\n",
    "    for j in range(len(gridAtt)):\n",
    "        for n in nList[j]:\n",
    "            edges.append((j+offset,n+offset))\n",
    "            graphN[j+offset].append(n+offset)\n",
    "    gridAttTemp, gridElTemp = nimplex.embeddedpair_simplex_grid_fractional_py(terncp, ndiv)\n",
    "    compositions += gridElTemp\n",
    "    \n",
    "    # Attach identifier to each composition\n",
    "    compositions_with_id.extend([(comp, i) for comp in gridElTemp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary composition position ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0]) has id 0\n",
      "Ternary composition position ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0]) has id 1\n",
      "Ternary composition position ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 1]) has id 2\n",
      "Ternary composition position ([1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0]) has id 3\n",
      "Ternary composition position ([1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1]) has id 4\n",
      "Ternary composition position ([1, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1]) has id 5\n",
      "Ternary composition position ([0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0]) has id 6\n",
      "Ternary composition position ([0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1]) has id 7\n",
      "Ternary composition position ([0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1]) has id 8\n",
      "Ternary composition position ([0, 0, 1, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1]) has id 9\n"
     ]
    }
   ],
   "source": [
    "# Example: Access ternaries_CompPos with their identifiers\n",
    "for terncp, ternary_id in ternaries_with_id:\n",
    "    print(f\"Ternary composition position {terncp} has id {ternary_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for ternary, id in ternaries_with_id:\n",
    "    composition_key = ''.join(elementalSpaceComponents[i] for i in range(len(elementalSpaceComponents)) if any(ternary[j][i] for j in range(len(ternary))))\n",
    "    mapping[composition_key] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination: CrFeNi, ID: 0, Elements: ['Cr', 'Fe', 'Ni']\n",
      "Combination: CrFeTi, ID: 1, Elements: ['Cr', 'Fe', 'Ti']\n",
      "Combination: CrFeV, ID: 2, Elements: ['Cr', 'Fe', 'V']\n",
      "Combination: CrNiTi, ID: 3, Elements: ['Cr', 'Ni', 'Ti']\n",
      "Combination: CrNiV, ID: 4, Elements: ['Cr', 'Ni', 'V']\n",
      "Combination: CrTiV, ID: 5, Elements: ['Cr', 'Ti', 'V']\n",
      "Combination: FeNiTi, ID: 6, Elements: ['Fe', 'Ni', 'Ti']\n",
      "Combination: FeNiV, ID: 7, Elements: ['Fe', 'Ni', 'V']\n",
      "Combination: FeTiV, ID: 8, Elements: ['Fe', 'Ti', 'V']\n",
      "Combination: NiTiV, ID: 9, Elements: ['Ni', 'Ti', 'V']\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for ternary, id in ternaries_with_id:\n",
    "    composition_key = ''.join(elementalSpaceComponents[i] for i in range(len(elementalSpaceComponents)) if any(ternary[j][i] for j in range(len(ternary))))\n",
    "    individual_elements = [elementalSpaceComponents[i] for i in range(len(elementalSpaceComponents)) if any(ternary[j][i] for j in range(len(ternary)))]\n",
    "    mapping[composition_key] = {\n",
    "        'id': id,\n",
    "        'elements': individual_elements\n",
    "    }\n",
    "\n",
    "# Print the mapping to see the result\n",
    "for key, value in mapping.items():\n",
    "    print(f\"Combination: {key}, ID: {value['id']}, Elements: {value['elements']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CrFeNi': {'id': 0, 'elements': ['Cr', 'Fe', 'Ni']},\n",
       " 'CrFeTi': {'id': 1, 'elements': ['Cr', 'Fe', 'Ti']},\n",
       " 'CrFeV': {'id': 2, 'elements': ['Cr', 'Fe', 'V']},\n",
       " 'CrNiTi': {'id': 3, 'elements': ['Cr', 'Ni', 'Ti']},\n",
       " 'CrNiV': {'id': 4, 'elements': ['Cr', 'Ni', 'V']},\n",
       " 'CrTiV': {'id': 5, 'elements': ['Cr', 'Ti', 'V']},\n",
       " 'FeNiTi': {'id': 6, 'elements': ['Fe', 'Ni', 'Ti']},\n",
       " 'FeNiV': {'id': 7, 'elements': ['Fe', 'Ni', 'V']},\n",
       " 'FeTiV': {'id': 8, 'elements': ['Fe', 'Ti', 'V']},\n",
       " 'NiTiV': {'id': 9, 'elements': ['Ni', 'Ti', 'V']}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_duplicates(lst):\n",
    "#     duplicates_counts = {}\n",
    "#     for item in lst:\n",
    "#         # Use the string representation for complex/unhashable types\n",
    "#         item_str = str(item)\n",
    "#         if item_str in duplicates_counts:\n",
    "#             duplicates_counts[item_str] += 1\n",
    "#         else:\n",
    "#             duplicates_counts[item_str] = 1\n",
    "\n",
    "#     # Filter out items that only appear once\n",
    "#     duplicates = {item: count for item, count in duplicates_counts.items() if count > 1}\n",
    "    \n",
    "#     if not duplicates:\n",
    "#         return \"No duplicates found in the list.\"\n",
    "#     else:\n",
    "#         result = \"Duplicates found:\"\n",
    "#         for item, count in duplicates.items():\n",
    "#             result += f\"{item} appears {count} times\"\n",
    "#         return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_duplicates(compositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cr', 'Fe'): occurs between ternary [(0, 1), (0, 2), (1, 2)]\n",
      "('Cr', 'Ni'): occurs between ternary [(0, 3), (0, 4), (3, 4)]\n",
      "('Fe', 'Ni'): occurs between ternary [(0, 6), (0, 7), (6, 7)]\n",
      "('Cr', 'Ti'): occurs between ternary [(1, 3), (1, 5), (3, 5)]\n",
      "('Fe', 'Ti'): occurs between ternary [(1, 6), (1, 8), (6, 8)]\n",
      "('Cr', 'V'): occurs between ternary [(2, 4), (2, 5), (4, 5)]\n",
      "('Fe', 'V'): occurs between ternary [(2, 7), (2, 8), (7, 8)]\n",
      "('Ni', 'Ti'): occurs between ternary [(3, 6), (3, 9), (6, 9)]\n",
      "('Ni', 'V'): occurs between ternary [(4, 7), (4, 9), (7, 9)]\n",
      "('Ti', 'V'): occurs between ternary [(5, 8), (5, 9), (8, 9)]\n"
     ]
    }
   ],
   "source": [
    "stitchingBinaries = {}\n",
    "\n",
    "for i, combo1 in enumerate(ternaries):\n",
    "    for j, combo2 in enumerate(ternaries[i+1:], start=i+1):\n",
    "        common = set(combo1) & set(combo2)\n",
    "        if len(common) == 2:\n",
    "            overlap = tuple(sorted(common))\n",
    "            if overlap not in stitchingBinaries:\n",
    "                stitchingBinaries[overlap] = []\n",
    "            stitchingBinaries[overlap].append((i, j))\n",
    "\n",
    "for overlap, pairs in stitchingBinaries.items():\n",
    "    print(f\"{overlap}: occurs between ternary {pairs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitching 0 and 1 at ('Cr', 'Fe') from [20, 19, 17, 14, 10, 5] to [41, 40, 38, 35, 31, 26]\n",
      "Stitching 0 and 2 at ('Cr', 'Fe') from [20, 19, 17, 14, 10, 5] to [62, 61, 59, 56, 52, 47]\n",
      "Stitching 1 and 2 at ('Cr', 'Fe') from [41, 40, 38, 35, 31, 26] to [62, 61, 59, 56, 52, 47]\n",
      "Stitching 0 and 3 at ('Cr', 'Ni') from [20, 18, 15, 11, 6, 0] to [83, 82, 80, 77, 73, 68]\n",
      "Stitching 0 and 4 at ('Cr', 'Ni') from [20, 18, 15, 11, 6, 0] to [104, 103, 101, 98, 94, 89]\n",
      "Stitching 3 and 4 at ('Cr', 'Ni') from [83, 82, 80, 77, 73, 68] to [104, 103, 101, 98, 94, 89]\n",
      "Stitching 0 and 6 at ('Fe', 'Ni') from [5, 4, 3, 2, 1, 0] to [146, 145, 143, 140, 136, 131]\n",
      "Stitching 0 and 7 at ('Fe', 'Ni') from [5, 4, 3, 2, 1, 0] to [167, 166, 164, 161, 157, 152]\n",
      "Stitching 6 and 7 at ('Fe', 'Ni') from [146, 145, 143, 140, 136, 131] to [167, 166, 164, 161, 157, 152]\n",
      "Stitching 1 and 3 at ('Cr', 'Ti') from [41, 39, 36, 32, 27, 21] to [83, 81, 78, 74, 69, 63]\n",
      "Stitching 1 and 5 at ('Cr', 'Ti') from [41, 39, 36, 32, 27, 21] to [125, 124, 122, 119, 115, 110]\n",
      "Stitching 3 and 5 at ('Cr', 'Ti') from [83, 81, 78, 74, 69, 63] to [125, 124, 122, 119, 115, 110]\n",
      "Stitching 1 and 6 at ('Fe', 'Ti') from [26, 25, 24, 23, 22, 21] to [146, 144, 141, 137, 132, 126]\n",
      "Stitching 1 and 8 at ('Fe', 'Ti') from [26, 25, 24, 23, 22, 21] to [188, 187, 185, 182, 178, 173]\n",
      "Stitching 6 and 8 at ('Fe', 'Ti') from [146, 144, 141, 137, 132, 126] to [188, 187, 185, 182, 178, 173]\n",
      "Stitching 2 and 4 at ('Cr', 'V') from [62, 60, 57, 53, 48, 42] to [104, 102, 99, 95, 90, 84]\n",
      "Stitching 2 and 5 at ('Cr', 'V') from [62, 60, 57, 53, 48, 42] to [125, 123, 120, 116, 111, 105]\n",
      "Stitching 4 and 5 at ('Cr', 'V') from [104, 102, 99, 95, 90, 84] to [125, 123, 120, 116, 111, 105]\n",
      "Stitching 2 and 7 at ('Fe', 'V') from [47, 46, 45, 44, 43, 42] to [167, 165, 162, 158, 153, 147]\n",
      "Stitching 2 and 8 at ('Fe', 'V') from [47, 46, 45, 44, 43, 42] to [188, 186, 183, 179, 174, 168]\n",
      "Stitching 7 and 8 at ('Fe', 'V') from [167, 165, 162, 158, 153, 147] to [188, 186, 183, 179, 174, 168]\n",
      "Stitching 3 and 6 at ('Ni', 'Ti') from [68, 67, 66, 65, 64, 63] to [131, 130, 129, 128, 127, 126]\n",
      "Stitching 3 and 9 at ('Ni', 'Ti') from [68, 67, 66, 65, 64, 63] to [209, 208, 206, 203, 199, 194]\n",
      "Stitching 6 and 9 at ('Ni', 'Ti') from [131, 130, 129, 128, 127, 126] to [209, 208, 206, 203, 199, 194]\n",
      "Stitching 4 and 7 at ('Ni', 'V') from [89, 88, 87, 86, 85, 84] to [152, 151, 150, 149, 148, 147]\n",
      "Stitching 4 and 9 at ('Ni', 'V') from [89, 88, 87, 86, 85, 84] to [209, 207, 204, 200, 195, 189]\n",
      "Stitching 7 and 9 at ('Ni', 'V') from [152, 151, 150, 149, 148, 147] to [209, 207, 204, 200, 195, 189]\n",
      "Stitching 5 and 8 at ('Ti', 'V') from [110, 109, 108, 107, 106, 105] to [173, 172, 171, 170, 169, 168]\n",
      "Stitching 5 and 9 at ('Ti', 'V') from [110, 109, 108, 107, 106, 105] to [194, 193, 192, 191, 190, 189]\n",
      "Stitching 8 and 9 at ('Ti', 'V') from [173, 172, 171, 170, 169, 168] to [194, 193, 192, 191, 190, 189]\n"
     ]
    }
   ],
   "source": [
    "for stitchingBinary, ternaryPairList in stitchingBinaries.items():\n",
    "    for ternaryPair in ternaryPairList:\n",
    "        ternary1, ternary2 = ternaryPair[0], ternaryPair[1]\n",
    "        stitching1 = stitching.findStitchingPoints_py(\n",
    "            3, ndiv, \n",
    "            components=ternaries[ternary1],\n",
    "            offset=ternary1*len(gridAtt)\n",
    "            )[\"-\".join(stitchingBinary)]\n",
    "        stitching2 = stitching.findStitchingPoints_py(\n",
    "            3, ndiv, \n",
    "            components=ternaries[ternary2],\n",
    "            offset=ternary2*len(gridAtt)\n",
    "            )[\"-\".join(stitchingBinary)]\n",
    "        print(f\"Stitching {ternary1} and {ternary2} at {stitchingBinary} from {stitching1} to {stitching2}\")\n",
    "        for i, j in zip(stitching1, stitching2):\n",
    "            edges.append((i, j))\n",
    "            graphNS[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique phases for ammap/databases/Co-Cr-Fe-Ni-V_choi2019.TDB: ['FCC_A1', 'BCC_A2', 'L12_FCC', 'B2_BCC', 'SIGMA', 'HIGH_SIGMA', 'NI2V', 'LIQUID', 'NI2V7', 'COV3', 'HCP_A3', 'M3V']\n",
      "Unique phases for ammap/databases/Cr-Fe-Ti_wang2017.tdb: ['C36', 'BCC_B2', 'FCC_A1', 'BCC_A2', 'TI5CR7FE17', 'SIGMA', 'C14', 'LIQUID', 'C15', 'HCP_A3']\n",
      "Unique phases for ammap/databases/Cr-Fe-Ni_miettinen1999.tdb: ['FCC_A1', 'BCC_A2', 'SIGMA', 'LIQUID', 'HCP_A3']\n",
      "Unique phases for ammap/databases/Cr-Ni-Ti_huang2018.tdb: ['NITI2', 'FCC_A1', 'BCC_A2', 'LAVES_C36', 'LAVES_C15', 'LIQUID', 'LAVES_C14', 'NI3TI', 'HCP_A3', 'NITI']\n",
      "Unique phases for ammap/databases/Cr-Ti-V_ghosh2002.tdb: ['BCC_A2', 'LAVES_C36', 'LAVES_C15', 'LAVES_C14', 'LIQUID', 'HCP_A3']\n",
      "Unique phases for ammap/databases/Fe-Ni-Ti_dekeyzer2009.tdb: ['NITI2', 'FCC4', 'C14', 'BCC2', 'A2', 'LIQUID', 'A1', 'NI3TI', 'A3']\n",
      "Unique phases for ammap/databases/Fe-Ni-V_zhao2014.tdb: ['D022_NI3V', 'A15_NI2V7', 'FCC_A1', 'HCP_A3', 'BCC_A2', 'CUB_A13', 'SIGMA', 'A2_BCC', 'LAVES_C15', 'LIQUID', 'LAVES_C14', 'NI2V', 'FE4N', 'CBCC_A12']\n",
      "Unique phases for ammap/databases/Fe-Ti-V_guo2012.TDB: ['FCC_A1', 'BCC_A2', 'SIGMA', 'C14', 'B2', 'LIQUID', 'HCP_A3']\n",
      "Unique phases for ammap/databases/Ni-Ti-V_zou2018.tdb: ['NITI2', 'FCC_A1', 'HCP_A3', 'BCC_A2', 'CUB_A13', 'NI3V', 'NIV3', 'SIGMA', 'B2', 'LAVES_C15', 'LIQUID', 'LAVES_C14', 'DIAMOND_A4', 'NI2V', 'NI3TI', 'BCT_A5', 'CBCC_A12']\n"
     ]
    }
   ],
   "source": [
    "from pycalphad import Database\n",
    "\n",
    "# List of database file paths\n",
    "db_files = [\n",
    "    \"ammap/databases/Co-Cr-Fe-Ni-V_choi2019.TDB\",\n",
    "    \"ammap/databases/Cr-Fe-Ti_wang2017.tdb\",\n",
    "    \"ammap/databases/Cr-Fe-Ni_miettinen1999.tdb\",\n",
    "    \"ammap/databases/Cr-Ni-Ti_huang2018.tdb\",\n",
    "    \"ammap/databases/Cr-Ti-V_ghosh2002.tdb\",\n",
    "    \"ammap/databases/Fe-Ni-Ti_dekeyzer2009.tdb\",\n",
    "    \"ammap/databases/Fe-Ni-V_zhao2014.tdb\",\n",
    "    \"ammap/databases/Fe-Ti-V_guo2012.TDB\",\n",
    "    \"ammap/databases/Ni-Ti-V_zou2018.tdb\"\n",
    "]\n",
    "\n",
    "# Dictionary to store unique phases for each database\n",
    "unique_phases = {}\n",
    "\n",
    "# Iterate through each database file\n",
    "for db_file in db_files:\n",
    "    dbf = Database(db_file)\n",
    "    phases = list(set(dbf.phases.keys()))\n",
    "    unique_phases[db_file] = phases\n",
    "\n",
    "# Print unique phases for each database\n",
    "for db_file, phases in unique_phases.items():\n",
    "    print(f\"Unique phases for {db_file}: {phases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cr', 'Fe', 'Ni', 'Ti', 'V']\n",
      "Loaded TDB file with phases considered: ['NITI2', 'FCC_A1', 'HCP_A3', 'BCC_A2', 'CUB_A13', 'NI3V', 'NIV3', 'SIGMA', 'B2', 'LAVES_C15', 'LIQUID', 'LAVES_C14', 'DIAMOND_A4', 'NI2V', 'NI3TI', 'BCT_A5', 'CBCC_A12']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#dbf = Database(\"CrHfMoNbTaTiVWZr_9element_Feb2023.tdb\")\n",
    "phases = list(set(dbf.phases.keys()))\n",
    "print(elementalSpaceComponents)\n",
    "print(f'Loaded TDB file with phases considered: {phases}')\n",
    "#from myPycalphadCallable import equilibrium_callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ocean/projects/dmr190011p/arichte1/micromamba/envs/v2ammap/lib/python3.11/site-packages/pycalphad/model.py:1278: UserWarning: The order-disorder model for \"FCC4\" has a contribution from the physical property model `magnetic_energy`. Partitioned physical properties are not correctly substituted into the disordered part of the energy. THE GIBBS ENERGY CALCULATED FOR THIS PHASE MAY BE INCORRECT. Please see the discussion in https://github.com/pycalphad/pycalphad/pull/311 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported equilibrium_callable_CrFeTi_08bbfb9a: <function equilibrium_callable at 0x7f68eb2f1760>\n",
      "Imported equilibrium_callable_CrFeV_ab1edb07: <function equilibrium_callable at 0x7f68eb165c60>\n",
      "Imported equilibrium_callable_CrNiTi_a9f6f2ff: <function equilibrium_callable at 0x7f68e2adcb80>\n",
      "Imported equilibrium_callable_NiTiV_1d83c99c: <function equilibrium_callable at 0x7f68e2954720>\n",
      "Imported equilibrium_callable_NiCrV_b7aba9ab: <function equilibrium_callable at 0x7f68eb10e2a0>\n",
      "Imported equilibrium_callable_NiCrFe_f434a6d9: <function equilibrium_callable at 0x7f68e217e5c0>\n",
      "Imported equilibrium_callable_FeTiV_fa95b3ee: <function equilibrium_callable at 0x7f68e1f95120>\n",
      "Imported equilibrium_callable_FeNiV_b9b0384d: <function equilibrium_callable at 0x7f68e215fe20>\n",
      "Imported equilibrium_callable_CrTiV_ed4c332b: <function equilibrium_callable at 0x7f68e1a10680>\n",
      "Imported equilibrium_callable_FeNiTi_06a49695: <function equilibrium_callable at 0x7f68e169b6a0>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "\n",
    "# Directory containing the equilibrium files\n",
    "directory = \"ammap/callables/multi_system_equilibrium_and_scheil\"\n",
    "\n",
    "# Get all files starting with \"equilibrium\"\n",
    "equilibrium_files = [f for f in os.listdir(directory) if f.startswith(\"equilibrium\") and f.endswith(\".py\")]\n",
    "\n",
    "# Dictionary to store imported callables with unique names\n",
    "equilibrium_callables = {}\n",
    "\n",
    "# Import each equilibrium file and store the callable with a unique name\n",
    "for file in equilibrium_files:\n",
    "    module_name = file[:-3]  # Remove the .py extension\n",
    "    module_path = f\"ammap.callables.multi_system_equilibrium_and_scheil.{module_name}\"\n",
    "    module = importlib.import_module(module_path)\n",
    "    callable_name = f\"{module_name}\"\n",
    "    equilibrium_callables[callable_name] = getattr(module, \"equilibrium_callable\")\n",
    "\n",
    "# Print the imported callables\n",
    "for name, func in equilibrium_callables.items():\n",
    "    print(f\"Imported {name}: {func}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ocean/projects/dmr190011p/arichte1/micromamba/envs/v2ammap/lib/python3.11/site-packages/pycalphad/model.py:1278: UserWarning: The order-disorder model for \"FCC4\" has a contribution from the physical property model `magnetic_energy`. Partitioned physical properties are not correctly substituted into the disordered part of the energy. THE GIBBS ENERGY CALCULATED FOR THIS PHASE MAY BE INCORRECT. Please see the discussion in https://github.com/pycalphad/pycalphad/pull/311 for more details.\n",
      "  warnings.warn(\n",
      "/ocean/projects/dmr190011p/arichte1/micromamba/envs/v2ammap/lib/python3.11/site-packages/pycalphad/io/tdb.py:293: UserWarning: The type definition character `&` in `TYPE_DEFINITION & GES A_P_D A2_BCC MAGNETIC -1.0 4.00000E-01 ` is not used by any phase.\n",
      "  warnings.warn(f\"The type definition character `{typechar}` in `TYPE_DEFINITION {typechar} {line}` is not used by any phase.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported scheil_callable_FeNiTi_06a49695: <function scheil_callable at 0x7f68e169b7e0>\n",
      "Imported scheil_callable_NiCrFe_f434a6d9: <function scheil_callable at 0x7f68e17c62a0>\n",
      "Imported scheil_callable_CrNiTi_a9f6f2ff: <function scheil_callable at 0x7f68e169a3e0>\n",
      "Imported scheil_callable_FeNiV_b9b0384d: <function scheil_callable at 0x7f68debab380>\n",
      "Imported scheil_callable_CrFeV_ab1edb07: <function scheil_callable at 0x7f68deb9f920>\n",
      "Imported scheil_callable_NiCrV_b7aba9ab: <function scheil_callable at 0x7f68de314540>\n",
      "Imported scheil_callable_FeTiV_fa95b3ee: <function scheil_callable at 0x7f68de11c2c0>\n",
      "Imported scheil_callable_CrTiV_ed4c332b: <function scheil_callable at 0x7f68de325ee0>\n",
      "Imported scheil_callable_NiTiV_1d83c99c: <function scheil_callable at 0x7f68de314c20>\n",
      "Imported scheil_callable_CrFeTi_08bbfb9a: <function scheil_callable at 0x7f68dda70b80>\n"
     ]
    }
   ],
   "source": [
    "# Get all files starting with \"scheil\"\n",
    "scheil_files = [f for f in os.listdir(directory) if f.startswith(\"scheil\") and f.endswith(\".py\")]\n",
    "scheil_callables = {}\n",
    "\n",
    "for file in scheil_files:\n",
    "    module_name = file[:-3]\n",
    "    module_path = f\"ammap.callables.multi_system_equilibrium_and_scheil.{module_name}\"\n",
    "    module = importlib.import_module(module_path)\n",
    "    callable_name = f\"{module_name}\"\n",
    "    scheil_callables[callable_name] = getattr(module, \"scheil_callable\")\n",
    "\n",
    "for name, func in scheil_callables.items():\n",
    "    print(f\"Imported {name}: {func}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        middle_part = parts[2]\n",
    "        if middle_part in element_mapping:\n",
    "            return middle_part, element_mapping[middle_part]\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_mapping=mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: equilibrium_callable_CrFeTi_08bbfb9a\n",
      "The mapping number for CrFeTi is 1\n",
      "Elements: ['Cr', 'Fe', 'Ti']\n",
      "---\n",
      "Key: equilibrium_callable_CrFeV_ab1edb07\n",
      "The mapping number for CrFeV is 2\n",
      "Elements: ['Cr', 'Fe', 'V']\n",
      "---\n",
      "Key: equilibrium_callable_CrNiTi_a9f6f2ff\n",
      "The mapping number for CrNiTi is 3\n",
      "Elements: ['Cr', 'Ni', 'Ti']\n",
      "---\n",
      "Key: equilibrium_callable_NiTiV_1d83c99c\n",
      "The mapping number for NiTiV is 9\n",
      "Elements: ['Ni', 'Ti', 'V']\n",
      "---\n",
      "Key: equilibrium_callable_NiCrV_b7aba9ab\n",
      "The mapping number for NiCrV is 4\n",
      "Elements: ['Cr', 'Ni', 'V']\n",
      "---\n",
      "Key: equilibrium_callable_NiCrFe_f434a6d9\n",
      "The mapping number for NiCrFe is 0\n",
      "Elements: ['Cr', 'Fe', 'Ni']\n",
      "---\n",
      "Key: equilibrium_callable_FeTiV_fa95b3ee\n",
      "The mapping number for FeTiV is 8\n",
      "Elements: ['Fe', 'Ti', 'V']\n",
      "---\n",
      "Key: equilibrium_callable_FeNiV_b9b0384d\n",
      "The mapping number for FeNiV is 7\n",
      "Elements: ['Fe', 'Ni', 'V']\n",
      "---\n",
      "Key: equilibrium_callable_CrTiV_ed4c332b\n",
      "The mapping number for CrTiV is 5\n",
      "Elements: ['Cr', 'Ti', 'V']\n",
      "---\n",
      "Key: equilibrium_callable_FeNiTi_06a49695\n",
      "The mapping number for FeNiTi is 6\n",
      "Elements: ['Fe', 'Ni', 'Ti']\n",
      "---\n",
      "Key: scheil_callable_FeNiTi_06a49695\n",
      "The mapping number for FeNiTi is 6\n",
      "Elements: ['Fe', 'Ni', 'Ti']\n",
      "---\n",
      "Key: scheil_callable_NiCrFe_f434a6d9\n",
      "The mapping number for NiCrFe is 0\n",
      "Elements: ['Cr', 'Fe', 'Ni']\n",
      "---\n",
      "Key: scheil_callable_CrNiTi_a9f6f2ff\n",
      "The mapping number for CrNiTi is 3\n",
      "Elements: ['Cr', 'Ni', 'Ti']\n",
      "---\n",
      "Key: scheil_callable_FeNiV_b9b0384d\n",
      "The mapping number for FeNiV is 7\n",
      "Elements: ['Fe', 'Ni', 'V']\n",
      "---\n",
      "Key: scheil_callable_CrFeV_ab1edb07\n",
      "The mapping number for CrFeV is 2\n",
      "Elements: ['Cr', 'Fe', 'V']\n",
      "---\n",
      "Key: scheil_callable_NiCrV_b7aba9ab\n",
      "The mapping number for NiCrV is 4\n",
      "Elements: ['Cr', 'Ni', 'V']\n",
      "---\n",
      "Key: scheil_callable_FeTiV_fa95b3ee\n",
      "The mapping number for FeTiV is 8\n",
      "Elements: ['Fe', 'Ti', 'V']\n",
      "---\n",
      "Key: scheil_callable_CrTiV_ed4c332b\n",
      "The mapping number for CrTiV is 5\n",
      "Elements: ['Cr', 'Ti', 'V']\n",
      "---\n",
      "Key: scheil_callable_NiTiV_1d83c99c\n",
      "The mapping number for NiTiV is 9\n",
      "Elements: ['Ni', 'Ti', 'V']\n",
      "---\n",
      "Key: scheil_callable_CrFeTi_08bbfb9a\n",
      "The mapping number for CrFeTi is 1\n",
      "Elements: ['Cr', 'Fe', 'Ti']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def process_key(key):\n",
    "    parts = key.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        middle_part = parts[2]\n",
    "        if middle_part in mapping:\n",
    "            return middle_part, mapping[middle_part]['id'], mapping[middle_part]['elements']\n",
    "        \n",
    "        # If direct matching fails, try matching by elements\n",
    "        middle_elements = set(middle_part[i:i+2] for i in range(0, len(middle_part), 2))\n",
    "        for map_key, value in mapping.items():\n",
    "            if set(value['elements']) == middle_elements:\n",
    "                return middle_part, value['id'], value['elements']\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "# Process each key in the equilibrium_callables dictionary\n",
    "id_to_callable = {}\n",
    "for key in equilibrium_callables:\n",
    "    middle_part, mapping_id, elements = process_key(key)\n",
    "    if middle_part and mapping_id is not None:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"The mapping number for {middle_part} is {mapping_id}\")\n",
    "        print(f\"Elements: {elements}\")\n",
    "        print(\"---\")\n",
    "        id_to_callable[mapping_id] = key\n",
    "    else:\n",
    "        print(f\"No mapping found for key: {key}\")\n",
    "        print(\"---\")\n",
    "\n",
    "sc_id_to_callable = {}\n",
    "for key in scheil_callables:\n",
    "    middle_part, mapping_id, elements = process_key(key)\n",
    "    if middle_part and mapping_id is not None:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"The mapping number for {middle_part} is {mapping_id}\")\n",
    "        print(f\"Elements: {elements}\")\n",
    "        print(\"---\")\n",
    "        sc_id_to_callable[mapping_id] = key\n",
    "    else:\n",
    "        print(f\"No mapping found for key: {key}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'equilibrium_callable_CrFeTi_08bbfb9a', 2: 'equilibrium_callable_CrFeV_ab1edb07', 3: 'equilibrium_callable_CrNiTi_a9f6f2ff', 9: 'equilibrium_callable_NiTiV_1d83c99c', 4: 'equilibrium_callable_NiCrV_b7aba9ab', 0: 'equilibrium_callable_NiCrFe_f434a6d9', 8: 'equilibrium_callable_FeTiV_fa95b3ee', 7: 'equilibrium_callable_FeNiV_b9b0384d', 5: 'equilibrium_callable_CrTiV_ed4c332b', 6: 'equilibrium_callable_FeNiTi_06a49695'}\n",
      "{6: 'scheil_callable_FeNiTi_06a49695', 0: 'scheil_callable_NiCrFe_f434a6d9', 3: 'scheil_callable_CrNiTi_a9f6f2ff', 7: 'scheil_callable_FeNiV_b9b0384d', 2: 'scheil_callable_CrFeV_ab1edb07', 4: 'scheil_callable_NiCrV_b7aba9ab', 8: 'scheil_callable_FeTiV_fa95b3ee', 5: 'scheil_callable_CrTiV_ed4c332b', 9: 'scheil_callable_NiTiV_1d83c99c', 1: 'scheil_callable_CrFeTi_08bbfb9a'}\n"
     ]
    }
   ],
   "source": [
    "print(id_to_callable)\n",
    "print(sc_id_to_callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0.0, 0.0, 1.0, 0.0, 0.0], 0),\n",
       " ([0.0, 0.2, 0.8, 0.0, 0.0], 0),\n",
       " ([0.0, 0.4, 0.6, 0.0, 0.0], 0),\n",
       " ([0.0, 0.6, 0.4, 0.0, 0.0], 0),\n",
       " ([0.0, 0.8, 0.2, 0.0, 0.0], 0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compositions_with_id[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CrFeNi': {'id': 0, 'elements': ['Cr', 'Fe', 'Ni']},\n",
       " 'CrFeTi': {'id': 1, 'elements': ['Cr', 'Fe', 'Ti']},\n",
       " 'CrFeV': {'id': 2, 'elements': ['Cr', 'Fe', 'V']},\n",
       " 'CrNiTi': {'id': 3, 'elements': ['Cr', 'Ni', 'Ti']},\n",
       " 'CrNiV': {'id': 4, 'elements': ['Cr', 'Ni', 'V']},\n",
       " 'CrTiV': {'id': 5, 'elements': ['Cr', 'Ti', 'V']},\n",
       " 'FeNiTi': {'id': 6, 'elements': ['Fe', 'Ni', 'Ti']},\n",
       " 'FeNiV': {'id': 7, 'elements': ['Fe', 'Ni', 'V']},\n",
       " 'FeTiV': {'id': 8, 'elements': ['Fe', 'Ti', 'V']},\n",
       " 'NiTiV': {'id': 9, 'elements': ['Ni', 'Ti', 'V']}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_compositions(compositions_with_id, mapping):\n",
    "    element_order = elementalSpaceComponents\n",
    "    system_comps_with_id = []\n",
    "    reduced_compositions = []\n",
    "    \n",
    "    for composition, comp_id in compositions_with_id:\n",
    "        relevant_entry = next((entry for entry in mapping.values() if entry['id'] == comp_id), None)\n",
    "        if not relevant_entry:\n",
    "            continue\n",
    "        \n",
    "        relevant_indices = [element_order.index(elem) for elem in relevant_entry['elements']]\n",
    "        reduced_point = [composition[index] for index in relevant_indices]\n",
    "        system_comps_with_id.append((reduced_point, comp_id))\n",
    "        reduced_compositions.append(reduced_point)\n",
    "    \n",
    "    return system_comps_with_id, reduced_compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_comps_with_id, reduced_compositions = reduce_compositions(compositions_with_id, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting nodes: [0, 90, 20, 31, 13, 68, 22, 196, 104, 27, 9, 97, 137, 143, 85]\n",
      "Starting node: [0.0, 0.0, 1.0]\n",
      "Starting node: [0.2, 0.0, 0.8]\n",
      "Starting node: [1.0, 0.0, 0.0]\n",
      "Starting node: [0.2, 0.8, 0.0]\n",
      "Starting node: [0.4, 0.4, 0.2]\n",
      "Starting node: [0.0, 1.0, 0.0]\n",
      "Starting node: [0.0, 0.2, 0.8]\n",
      "Starting node: [0.2, 0.2, 0.6]\n",
      "Starting node: [1.0, 0.0, 0.0]\n",
      "Starting node: [0.2, 0.0, 0.8]\n",
      "Starting node: [0.2, 0.6, 0.2]\n",
      "Starting node: [0.4, 0.4, 0.2]\n",
      "Starting node: [0.4, 0.0, 0.6]\n",
      "Starting node: [0.6, 0.4, 0.0]\n",
      "Starting node: [0.0, 0.2, 0.8]\n"
     ]
    }
   ],
   "source": [
    "#startingNodes = [0, 90, 200, 310] + random.sample(range(len(reduced_compositions)), 11)\n",
    "startingNodes = [0, 90, 20, 31] + random.sample(range(len(reduced_compositions)), 11)\n",
    "print(f\"Starting nodes: {startingNodes}\")\n",
    "\n",
    "for startingNode in startingNodes:\n",
    "    print(f\"Starting node: {reduced_compositions[startingNode]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridFeasible = [None]*len(reduced_compositions)\n",
    "queue = startingNodes.copy()\n",
    "explored = set()\n",
    "calcCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the correct callable for a given composition\n",
    "def get_callable(composition):\n",
    "    for comp, id in compositions_with_id:\n",
    "        if comp == composition:\n",
    "            callable_name = id_to_callable.get(id)\n",
    "            if callable_name is None:\n",
    "                raise ValueError(f\"No callable name found for ID {id}\")\n",
    "            if callable_name in globals():\n",
    "                return globals()[callable_name]\n",
    "            else:\n",
    "                raise NameError(f\"Function '{callable_name}' not found in global scope\")\n",
    "    raise ValueError(f\"No callable found for composition {composition}\")\n",
    "\n",
    "def process_composition(elP):\n",
    "    try:\n",
    "        callable_func = get_callable(elP)\n",
    "        return callable_func(elP)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing composition {elP}: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the correct callable for a given composition\n",
    "def get_sc_callable(composition):\n",
    "    for comp, id in compositions_with_id:\n",
    "        if comp == composition:\n",
    "            callable_name = sc_id_to_callable.get(id)\n",
    "            if callable_name is None:\n",
    "                raise ValueError(f\"No callable name found for ID {id}\")\n",
    "            if callable_name in globals():\n",
    "                return globals()[callable_name]\n",
    "            else:\n",
    "                raise NameError(f\"Function '{callable_name}' not found in global scope\")\n",
    "    raise ValueError(f\"No callable found for composition {composition}\")\n",
    "\n",
    "def process_sc_composition(elP):\n",
    "    try:\n",
    "        callable_func = get_sc_callable(elP)\n",
    "        return callable_func(elP)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing composition {elP}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'equilibrium_callable_CrFeTi_08bbfb9a': <function equilibrium_callable at 0x7f68eb2f1760>, 'equilibrium_callable_CrFeV_ab1edb07': <function equilibrium_callable at 0x7f68eb165c60>, 'equilibrium_callable_CrNiTi_a9f6f2ff': <function equilibrium_callable at 0x7f68e2adcb80>, 'equilibrium_callable_NiTiV_1d83c99c': <function equilibrium_callable at 0x7f68e2954720>, 'equilibrium_callable_NiCrV_b7aba9ab': <function equilibrium_callable at 0x7f68eb10e2a0>, 'equilibrium_callable_NiCrFe_f434a6d9': <function equilibrium_callable at 0x7f68e217e5c0>, 'equilibrium_callable_FeTiV_fa95b3ee': <function equilibrium_callable at 0x7f68e1f95120>, 'equilibrium_callable_FeNiV_b9b0384d': <function equilibrium_callable at 0x7f68e215fe20>, 'equilibrium_callable_CrTiV_ed4c332b': <function equilibrium_callable at 0x7f68e1a10680>, 'equilibrium_callable_FeNiTi_06a49695': <function equilibrium_callable at 0x7f68e169b6a0>}\n",
      "{'scheil_callable_FeNiTi_06a49695': <function scheil_callable at 0x7f68e169b7e0>, 'scheil_callable_NiCrFe_f434a6d9': <function scheil_callable at 0x7f68e17c62a0>, 'scheil_callable_CrNiTi_a9f6f2ff': <function scheil_callable at 0x7f68e169a3e0>, 'scheil_callable_FeNiV_b9b0384d': <function scheil_callable at 0x7f68debab380>, 'scheil_callable_CrFeV_ab1edb07': <function scheil_callable at 0x7f68deb9f920>, 'scheil_callable_NiCrV_b7aba9ab': <function scheil_callable at 0x7f68de314540>, 'scheil_callable_FeTiV_fa95b3ee': <function scheil_callable at 0x7f68de11c2c0>, 'scheil_callable_CrTiV_ed4c332b': <function scheil_callable at 0x7f68de325ee0>, 'scheil_callable_NiTiV_1d83c99c': <function scheil_callable at 0x7f68de314c20>, 'scheil_callable_CrFeTi_08bbfb9a': <function scheil_callable at 0x7f68dda70b80>}\n"
     ]
    }
   ],
   "source": [
    "print(equilibrium_callables)\n",
    "print(scheil_callables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.0, 0.0, 1.0, 0.0, 0.0], 0)\n",
      "([0.2, 0.4, 0.0, 0.0, 0.4], 2)\n",
      "([0.6, 0.0, 0.2, 0.0, 0.2], 4)\n",
      "([0.0, 0.0, 0.6, 0.0, 0.4], 7)\n",
      "([0.0, 0.0, 0.4, 0.0, 0.6], 9)\n"
     ]
    }
   ],
   "source": [
    "sampled_compositions = compositions_with_id[::50]\n",
    "\n",
    "# Print the sampled compositions to verify\n",
    "for composition in sampled_compositions:\n",
    "    print(composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phases': ['HCP_A3'], 'PhaseFraction': [1.0000000000994484]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.4, 0.0, 0.6]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(equilibrium_callables['equilibrium_callable_CrNiTi_a9f6f2ff'](compositions[200]))\n",
    "compositions[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def get_equilibrium_callable(composition, id_to_callable, equilibrium_callables):\n",
    "    composition_id = composition[1]  # Get the ID from the composition tuple\n",
    "    #print(f\"Composition ID: {composition_id}\")\n",
    "    callable_name = id_to_callable.get(composition_id)\n",
    "    if callable_name is None:\n",
    "        raise ValueError(f\"No callable found for composition ID {composition_id}\")\n",
    "    callable_func = equilibrium_callables.get(callable_name)\n",
    "    if callable_func is None:\n",
    "        raise ValueError(f\"No callable function found for name {callable_name}\")\n",
    "    return callable_func\n",
    "\n",
    "def apply_equilibrium_callable(callable_and_position):\n",
    "    callable_func, position = callable_and_position\n",
    "    return callable_func(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def get_scheil_callable(composition, sc_id_to_callable, scheil_callables):\n",
    "    composition_id = composition[1]  # Get the ID from the composition tuple\n",
    "    #print(f\"Composition ID: {composition_id}\")\n",
    "    callable_name = sc_id_to_callable.get(composition_id)\n",
    "    if callable_name is None:\n",
    "        raise ValueError(f\"No callable found for composition ID {composition_id}\")\n",
    "    callable_func = scheil_callables.get(callable_name)\n",
    "    if callable_func is None:\n",
    "        raise ValueError(f\"No callable function found for name {callable_name}\")\n",
    "    return callable_func\n",
    "\n",
    "def apply_scheil_callable(callable_and_position):\n",
    "    callable_func, position = callable_and_position\n",
    "    return callable_func(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#WORKING\n",
    "while len(queue) > 0:\n",
    "    print(f\"Queue: {queue}\")\n",
    "    # Calculate feasibilities of the current queue\n",
    "    elPositions = [reduced_compositions[i] for i in queue]\n",
    "    print(elPositions)\n",
    "    # Create a list of equilibrium callables for each composition\n",
    "    equilibrium_callables_list = [get_equilibrium_callable(system_comps_with_id[i], id_to_callable, equilibrium_callables) for i in queue]\n",
    "    \n",
    "    if len(queue) > 3:\n",
    "        results = process_map(apply_equilibrium_callable, zip(equilibrium_callables_list, elPositions), max_workers=4)\n",
    "    else:\n",
    "        results = [ec(elP) for ec, elP in zip(equilibrium_callables_list, elPositions)]\n",
    "    \n",
    "    # Extract only the 'Phases' component from the results\n",
    "    phases = [result['Phases'] for result in results]\n",
    "    \n",
    "    feasibilities = [len(set(p) & set(['FCC_A1', 'BCC_A2', 'HCP_A3', 'B2_BCC','A2_FCC'])) == 0 and p != [] for p in phases]\n",
    "\n",
    "    calcCount += len(feasibilities)\n",
    "    explored = explored.union(queue)\n",
    "\n",
    "    # Create next queue based on neighbors of feasible points\n",
    "    nextQueue = set()\n",
    "    nextQueuePlusEquivalent = set()\n",
    "    for f, i in zip(feasibilities, queue):\n",
    "        # Explored point\n",
    "        gridFeasible[i] = f\n",
    "\n",
    "        # And equivalent explored points based on system stitching\n",
    "        explored = explored.union(graphNS[i])\n",
    "        for eq in graphNS[i]:\n",
    "            gridFeasible[eq] = f\n",
    "\n",
    "        # Expand to neighbors of the point and equivalent points (only if the node has been feasible)\n",
    "        if f:\n",
    "            # Node neighbors in the same subsystem\n",
    "            for n in graphN[i]:\n",
    "                if n not in explored and n not in nextQueuePlusEquivalent:\n",
    "                    nextQueue.add(n)\n",
    "                    nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "            # Equivalent nodes neighbors in other subsystems\n",
    "            for eq in graphNS[i]:\n",
    "                for n in graphN[eq]:\n",
    "                    if n not in explored and n not in nextQueuePlusEquivalent:\n",
    "                        nextQueue.add(n)\n",
    "                        nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "\n",
    "    print(f\"Calculations done: {calcCount:<5} | Explored points: {len(explored):<5}\")\n",
    "    queue = list(nextQueue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue: [0, 90, 20, 31, 13, 68, 22, 196, 104, 27, 9, 97, 137, 143, 85]\n",
      "[[0.0, 0.0, 1.0], [0.2, 0.0, 0.8], [1.0, 0.0, 0.0], [0.2, 0.8, 0.0], [0.4, 0.4, 0.2], [0.0, 1.0, 0.0], [0.0, 0.2, 0.8], [0.2, 0.2, 0.6], [1.0, 0.0, 0.0], [0.2, 0.0, 0.8], [0.2, 0.6, 0.2], [0.4, 0.4, 0.2], [0.4, 0.0, 0.6], [0.6, 0.4, 0.0], [0.0, 0.2, 0.8]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb83c377dfc247af8b8aa5d1ab6406b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations done: 15    | Explored points: 33   \n",
      "Queue: [1, 3, 4, 133, 6, 8, 10, 138, 140, 141, 14, 139, 142, 18, 19, 160, 163, 39, 177, 181, 60, 67, 84, 88, 91, 95, 106, 112]\n",
      "[[0.0, 0.2, 0.8], [0.0, 0.6, 0.4], [0.0, 0.8, 0.2], [0.2, 0.2, 0.6], [0.2, 0.0, 0.8], [0.2, 0.4, 0.4], [0.2, 0.8, 0.0], [0.4, 0.2, 0.4], [0.4, 0.6, 0.0], [0.6, 0.0, 0.4], [0.4, 0.6, 0.0], [0.4, 0.4, 0.2], [0.6, 0.2, 0.2], [0.8, 0.0, 0.2], [0.8, 0.2, 0.0], [0.4, 0.4, 0.2], [0.6, 0.2, 0.2], [0.8, 0.0, 0.2], [0.2, 0.6, 0.2], [0.4, 0.4, 0.2], [0.8, 0.0, 0.2], [0.0, 0.8, 0.2], [0.0, 0.0, 1.0], [0.0, 0.8, 0.2], [0.2, 0.2, 0.6], [0.4, 0.0, 0.6], [0.0, 0.2, 0.8], [0.2, 0.2, 0.6]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe25c19380b041d082eb178fe43f8973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations done: 43    | Explored points: 89   \n",
      "Queue: [2, 130, 5, 135, 7, 11, 12, 15, 144, 145, 16, 17, 151, 25, 153, 155, 156, 30, 159, 35, 165, 37, 168, 46, 175, 51, 57, 58, 190, 72, 79, 81, 93, 96, 100, 102, 107, 113, 117, 121]\n",
      "[[0.0, 0.4, 0.6], [0.0, 0.8, 0.2], [0.0, 1.0, 0.0], [0.2, 0.6, 0.2], [0.2, 0.2, 0.6], [0.4, 0.0, 0.6], [0.4, 0.2, 0.4], [0.6, 0.0, 0.4], [0.8, 0.0, 0.2], [0.8, 0.2, 0.0], [0.6, 0.2, 0.2], [0.6, 0.4, 0.0], [0.0, 0.8, 0.2], [0.0, 0.8, 0.2], [0.2, 0.0, 0.8], [0.2, 0.4, 0.4], [0.2, 0.6, 0.2], [0.2, 0.6, 0.2], [0.4, 0.2, 0.4], [0.4, 0.6, 0.0], [0.8, 0.0, 0.2], [0.6, 0.2, 0.2], [0.0, 0.0, 1.0], [0.0, 0.8, 0.2], [0.2, 0.2, 0.6], [0.2, 0.6, 0.2], [0.6, 0.0, 0.4], [0.6, 0.2, 0.2], [0.0, 0.2, 0.8], [0.2, 0.6, 0.2], [0.6, 0.2, 0.2], [0.8, 0.0, 0.2], [0.2, 0.6, 0.2], [0.4, 0.2, 0.4], [0.6, 0.2, 0.2], [0.8, 0.0, 0.2], [0.0, 0.4, 0.6], [0.2, 0.4, 0.4], [0.4, 0.2, 0.4], [0.6, 0.2, 0.2]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ea0dc76afb4218830d2237d6516f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations done: 83    | Explored points: 139  \n",
      "Queue: [162, 197, 76, 108, 80, 176, 114, 53, 150, 54, 184, 55, 154, 118, 188, 158]\n",
      "[[0.6, 0.0, 0.4], [0.2, 0.4, 0.4], [0.4, 0.4, 0.2], [0.0, 0.6, 0.4], [0.6, 0.4, 0.0], [0.2, 0.4, 0.4], [0.2, 0.6, 0.2], [0.4, 0.0, 0.6], [0.0, 0.6, 0.4], [0.4, 0.2, 0.4], [0.6, 0.2, 0.2], [0.4, 0.4, 0.2], [0.2, 0.2, 0.6], [0.4, 0.4, 0.2], [1.0, 0.0, 0.0], [0.4, 0.0, 0.6]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f986b5f19e45f1af5923e772d8f622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations done: 99    | Explored points: 159  \n",
      "Queue: [198, 109, 48, 49, 50]\n",
      "[[0.2, 0.6, 0.2], [0.0, 0.8, 0.2], [0.2, 0.0, 0.8], [0.2, 0.2, 0.6], [0.2, 0.4, 0.4]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3191f17ee646beb448a14c442836ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations done: 104   | Explored points: 166  \n",
      "Queue: [199, 42, 43, 44, 110]\n",
      "[[0.2, 0.8, 0.0], [0.0, 0.0, 1.0], [0.0, 0.2, 0.8], [0.0, 0.4, 0.6], [0.0, 1.0, 0.0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95bbd68d0ca49698ce39901dc0188a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations done: 109   | Explored points: 173  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "while len(queue) > 0:\n",
    "    print(f\"Queue: {queue}\")\n",
    "    # Calculate feasibilities of the current queue\n",
    "    elPositions = [reduced_compositions[i] for i in queue]\n",
    "    print(elPositions)\n",
    "    # Create a list of equilibrium callables for each composition\n",
    "    equilibrium_callables_list = [get_equilibrium_callable(system_comps_with_id[i], id_to_callable, equilibrium_callables) for i in queue]\n",
    "    \n",
    "    if len(queue) > 3:\n",
    "        results = process_map(apply_equilibrium_callable, zip(equilibrium_callables_list, elPositions), max_workers=4)\n",
    "    else:\n",
    "        results = [ec(elP) for ec, elP in zip(equilibrium_callables_list, elPositions)]\n",
    "    \n",
    "    # Extract only the 'Phases' component from the results\n",
    "    phases = [result['Phases'] for result in results]\n",
    "    \n",
    "    #feasibilities = [len(set(p) & set(['FCC_A1', 'BCC_A2', 'HCP_A3', 'B2_BCC','A2_FCC','L12_FCC','BCC2', 'A1', 'A2', 'A3', 'FCC4'])) == 0 and p != [] for p in phases]\n",
    "    feasibilities = [set(p).issubset(set(['FCC_A1', 'BCC_A2', 'HCP_A3', 'B2_BCC', 'A2_FCC', 'L12_FCC', 'BCC2', 'A1', 'A2', 'A3', 'FCC4'])) and p != [] for p in phases]\n",
    "\n",
    "    calcCount += len(feasibilities)\n",
    "    explored = explored.union(queue)\n",
    "\n",
    "    # Save the current step result and elPositions\n",
    "    results_list.append({\n",
    "        'queue': queue,\n",
    "        'elPositions': elPositions,\n",
    "        'results': results\n",
    "    })\n",
    "\n",
    "    # Create next queue based on neighbors of feasible points\n",
    "    nextQueue = set()\n",
    "    nextQueuePlusEquivalent = set()\n",
    "    for f, i in zip(feasibilities, queue):\n",
    "        # Explored point\n",
    "        gridFeasible[i] = f\n",
    "\n",
    "        # And equivalent explored points based on system stitching\n",
    "        explored = explored.union(graphNS[i])\n",
    "        for eq in graphNS[i]:\n",
    "            gridFeasible[eq] = f\n",
    "\n",
    "        # Expand to neighbors of the point and equivalent points (only if the node has been feasible)\n",
    "        if f:\n",
    "            # Node neighbors in the same subsystem\n",
    "            for n in graphN[i]:\n",
    "                if n not in explored and n not in nextQueuePlusEquivalent:\n",
    "                    nextQueue.add(n)\n",
    "                    nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "            # Equivalent nodes neighbors in other subsystems\n",
    "            for eq in graphNS[i]:\n",
    "                for n in graphN[eq]:\n",
    "                    if n not in explored and n not in nextQueuePlusEquivalent:\n",
    "                        nextQueue.add(n)\n",
    "                        nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "\n",
    "    print(f\"Calculations done: {calcCount:<5} | Explored points: {len(explored):<5}\")\n",
    "    queue = list(nextQueue)\n",
    "\n",
    "# Write the results to a JSON file\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the results from the JSON file\n",
    "with open('/ocean/projects/dmr190011p/arichte1/github_repo/AMMap/results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the merged results\n",
    "merged_results = {}\n",
    "\n",
    "# Iterate through each step in the data\n",
    "for step in data:\n",
    "    queue = step['queue']\n",
    "    results = step['results']\n",
    "    \n",
    "    # Merge the queue numbers with their associated result values\n",
    "    for q, result in zip(queue, results):\n",
    "        merged_results[q] = result\n",
    "\n",
    "# Convert the merged results dictionary to a list of dictionaries\n",
    "merged_results_list = [{'queue': q, 'result': result} for q, result in merged_results.items()]\n",
    "\n",
    "# Save the merged results to a new JSON file\n",
    "with open('merged_results.json', 'w') as f:\n",
    "    json.dump(merged_results_list, f, indent=4)\n",
    "with open('grid_feasible.json', 'w') as f:\n",
    "    json.dump(gridFeasible, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridFeasible1 = [None]*len(reduced_compositions)\n",
    "queue = startingNodes.copy()\n",
    "explored = set()\n",
    "calcCount = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "while len(queue) > 0:\n",
    "    print(f\"Queue: {queue}\")\n",
    "    # Calculate feasibilities of the current queue\n",
    "    elPositions = [reduced_compositions[i] for i in queue]\n",
    "    print(elPositions)\n",
    "    # Create a list of scheil callables for each composition\n",
    "    scheil_callables_list = [get_scheil_callable(system_comps_with_id[i], sc_id_to_callable, scheil_callables) for i in queue]\n",
    "    \n",
    "    if len(queue) > 3:\n",
    "        results = process_map(apply_scheil_callable, zip(scheil_callables_list, elPositions), max_workers=4)\n",
    "    else:\n",
    "        results = [sc(elP) for sc, elP in zip(scheil_callables_list, elPositions)]\n",
    "    \n",
    "    # Extract only the 'Phases' component from the results\n",
    "    phases = [result['finalPhase'] for result in results]\n",
    "    \n",
    "    feasibilities = [set(p).issubset(set(['FCC_A1', 'BCC_A2', 'HCP_A3', 'B2_BCC', 'A2_FCC', 'L12_FCC', 'BCC2', 'A1', 'A2', 'A3', 'FCC4'])) and p != [] for p in phases]\n",
    "\n",
    "    calcCount += len(feasibilities)\n",
    "    explored = explored.union(queue)\n",
    "\n",
    "    # Save the current step result and elPositions\n",
    "    results_list.append({\n",
    "        'queue': queue,\n",
    "        'elPositions': elPositions,\n",
    "        'results': results\n",
    "    })\n",
    "\n",
    "    # Create next queue based on neighbors of feasible points\n",
    "    nextQueue = set()\n",
    "    nextQueuePlusEquivalent = set()\n",
    "    for f, i in zip(feasibilities, queue):\n",
    "        # Explored point\n",
    "        gridFeasible1[i] = f\n",
    "\n",
    "        # And equivalent explored points based on system stitching\n",
    "        explored = explored.union(graphNS[i])\n",
    "        for eq in graphNS[i]:\n",
    "            gridFeasible1[eq] = f\n",
    "\n",
    "        # Expand to neighbors of the point and equivalent points (only if the node has been feasible)\n",
    "        if f:\n",
    "            # Node neighbors in the same subsystem\n",
    "            for n in graphN[i]:\n",
    "                if n not in explored and n not in nextQueuePlusEquivalent:\n",
    "                    nextQueue.add(n)\n",
    "                    nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "            # Equivalent nodes neighbors in other subsystems\n",
    "            for eq in graphNS[i]:\n",
    "                for n in graphN[eq]:\n",
    "                    if n not in explored and n not in nextQueuePlusEquivalent:\n",
    "                        nextQueue.add(n)\n",
    "                        nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "\n",
    "    print(f\"Calculations done: {calcCount:<5} | Explored points: {len(explored):<5}\")\n",
    "    queue = list(nextQueue)\n",
    "\n",
    "# Write the results to a JSON file\n",
    "with open('scheil_results.json', 'w') as f:\n",
    "    json.dump(results_list, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def apply_scheil_callable(args):\n",
    "    sc, elP = args\n",
    "    try:\n",
    "        return sc(elP)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing item: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "while len(queue) > 0:\n",
    "    print(f\"Queue: {queue}\")\n",
    "    # Calculate feasibilities of the current queue\n",
    "    elPositions = [reduced_compositions[i] for i in queue]\n",
    "    print(elPositions)\n",
    "    # Create a list of scheil callables for each composition\n",
    "    scheil_callables_list = [get_scheil_callable(system_comps_with_id[i], sc_id_to_callable, scheil_callables) for i in queue]\n",
    "    \n",
    "    if len(queue) > 3:\n",
    "        results = process_map(apply_scheil_callable, zip(scheil_callables_list, elPositions), max_workers=4)\n",
    "    else:\n",
    "        results = [apply_scheil_callable((sc, elP)) for sc, elP in zip(scheil_callables_list, elPositions)]\n",
    "    \n",
    "    # Filter out None values (errors) and process valid results\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "    \n",
    "    # Extract only the 'Phases' component from the valid results\n",
    "    phases = [result['finalPhase'] for result in valid_results]\n",
    "    \n",
    "    feasibilities = [set(p).issubset(set(['FCC_A1', 'BCC_A2', 'HCP_A3', 'B2_BCC', 'A2_FCC', 'L12_FCC', 'BCC2', 'A1', 'A2', 'A3', 'FCC4'])) and p != [] for p in phases]\n",
    "\n",
    "    calcCount += len(feasibilities)\n",
    "    explored = explored.union(queue)\n",
    "\n",
    "    # Save the current step result and elPositions\n",
    "    results_list.append({\n",
    "        'queue': queue,\n",
    "        'elPositions': elPositions,\n",
    "        'results': valid_results\n",
    "    })\n",
    "\n",
    "    # Create next queue based on neighbors of feasible points\n",
    "    nextQueue = set()\n",
    "    nextQueuePlusEquivalent = set()\n",
    "    for f, i in zip(feasibilities, queue):\n",
    "        # Explored point\n",
    "        gridFeasible1[i] = f\n",
    "\n",
    "        # And equivalent explored points based on system stitching\n",
    "        explored = explored.union(graphNS[i])\n",
    "        for eq in graphNS[i]:\n",
    "            gridFeasible1[eq] = f\n",
    "\n",
    "        # Expand to neighbors of the point and equivalent points (only if the node has been feasible)\n",
    "        if f:\n",
    "            # Node neighbors in the same subsystem\n",
    "            for n in graphN[i]:\n",
    "                if n not in explored and n not in nextQueuePlusEquivalent:\n",
    "                    nextQueue.add(n)\n",
    "                    nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "            # Equivalent nodes neighbors in other subsystems\n",
    "            for eq in graphNS[i]:\n",
    "                for n in graphN[eq]:\n",
    "                    if n not in explored and n not in nextQueuePlusEquivalent:\n",
    "                        nextQueue.add(n)\n",
    "                        nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "\n",
    "    print(f\"Calculations done: {calcCount:<5} | Explored points: {len(explored):<5}\")\n",
    "    queue = list(nextQueue)\n",
    "\n",
    "# Write the results to a JSON file\n",
    "with open('scheil_results.json', 'w') as f:\n",
    "    json.dump(results_list, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the results from the JSON file\n",
    "with open('/ocean/projects/dmr190011p/arichte1/github_repo/AMMap/scheil_results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the merged results\n",
    "merged_results = {}\n",
    "\n",
    "# Iterate through each step in the data\n",
    "for step in data:\n",
    "    queue = step['queue']\n",
    "    results = step['results']\n",
    "    \n",
    "    # Merge the queue numbers with their associated result values\n",
    "    for q, result in zip(queue, results):\n",
    "        merged_results[q] = result\n",
    "\n",
    "# Convert the merged results dictionary to a list of dictionaries\n",
    "merged_results_list = [{'queue': q, 'result': result} for q, result in merged_results.items()]\n",
    "\n",
    "# Save the merged results to a new JSON file\n",
    "with open('merged_scheil_results.json', 'w') as f:\n",
    "    json.dump(merged_results_list, f, indent=4)\n",
    "with open('grid_feasible1.json', 'w') as f:\n",
    "    json.dump(gridFeasible1, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the explored points, around 1040 should be feasible (i.e., satisfy the equilibrium constraint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathfinding.core.graph import Graph\n",
    "from pathfinding.finder.dijkstra import DijkstraFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFindEdges = []\n",
    "for edge in edges:\n",
    "    if gridFeasible[edge[0]] and gridFeasible[edge[1]]:\n",
    "        pathFindEdges.append([edge[0], edge[1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfindingGraph = Graph(edges=pathFindEdges, bi_directional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = DijkstraFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(pathfindingGraph.nodes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nodes in the graph:\", list(pathfindingGraph.nodes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_node_id = 194\n",
    "# end_node_id = 830\n",
    "start_node_id = 0#12\n",
    "end_node_id = 408\n",
    "\n",
    "# Check if the nodes exist in the graph\n",
    "if start_node_id in pathfindingGraph.nodes and end_node_id in pathfindingGraph.nodes:\n",
    "    path, runs = finder.find_path(\n",
    "        pathfindingGraph.node(start_node_id), \n",
    "        pathfindingGraph.node(end_node_id), \n",
    "        pathfindingGraph)\n",
    "    print(\"Path found:\", path)\n",
    "else:\n",
    "    print(f\"One or both of the nodes {start_node_id} and {end_node_id} do not exist in the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortestPath = [p.node_id for p in path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hover approximate formula for each point\n",
    "formulas = []\n",
    "for i, comp in enumerate(compositions):\n",
    "    formulas.append(f\"({i:>3}) \"+\"\".join([f\"{el}{100*v:.1f} \" if v>0 else \"\" for el, v in zip(elementalSpaceComponents, comp)]))\n",
    "\n",
    "# # Generate the projected grid\n",
    "# gridAtt_projected_df = pd.DataFrame(plotting.simplex2cartesian_py(gridAtt), columns=['x','y','z'])\n",
    "\n",
    "# # Attach pure component (alloy) labels to corners\n",
    "# pureComponentIndices = nimplex.pure_component_indexes_py(4, 12)\n",
    "# labels = ['']*len(gridAtt_projected_df)\n",
    "# for comp, idx in zip(attainableSpaceComponents, pureComponentIndices):\n",
    "#     labels[idx] = \"<b>\"+comp+\"</b>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, i in enumerate(shortestPath):\n",
    "    print(f\"{step+1:>2}: {formulas[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2ammap",
   "language": "python",
   "name": "v2ammap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
