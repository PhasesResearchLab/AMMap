{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMMap Tool for Additive Manufacturing Design, Alloy Discovery, and Path Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> ***(Please see https://github.com/amkrajewski/nimplex for setting up and utilizing nimplex)***\n",
    "\n",
    "--> You will additionally need `pathfinding` libraries to run part of this exercise. If you are running this in Codespaces, it has been pre-installed for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook is the current method of utilizing AMMap and through minor alterations can be changed to run AMMap on any system from an Input YAML file**\n",
    "\n",
    "**In this notebook, we will demonstrate how effortless it is to dramatically speed up the exploration of feasible compositional spaces in high dimensional spaces through employing `nimplex`'s graph representations that abstract the underlying problem and dimensionality.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nimplex and other necessary packages\n",
    "import nimplex\n",
    "import numpy as np\n",
    "from utils import stitching\n",
    "from IPython.display import clear_output\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from pycalphad import Database\n",
    "import os\n",
    "import importlib\n",
    "import json\n",
    "import igraph as ig\n",
    "import plotly.graph_objs as go\n",
    "import yaml\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML file\n",
    "yaml_file = 'publication_input.yaml'\n",
    "with open(yaml_file, 'r') as file:\n",
    "    yaml_content = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_CrTiV_ed4c332b.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_CrTiV_ed4c332b.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_NiCrV_b7aba9ab.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_NiCrV_b7aba9ab.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_CrFeV_ab1edb07.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_CrFeV_ab1edb07.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_NiCrFe_f434a6d9.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_NiCrFe_f434a6d9.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_CrFeTi_08bbfb9a.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_CrFeTi_08bbfb9a.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_CrNiTi_a9f6f2ff.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_CrNiTi_a9f6f2ff.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_FeNiTi_06a49695.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_FeNiTi_06a49695.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_FeNiV_b9b0384d.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_FeNiV_b9b0384d.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_FeTiV_fa95b3ee.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_FeTiV_fa95b3ee.py\n",
      "Equilibrium callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/equilibrium_callable_NiTiV_1d83c99c.py\n",
      "Scheil callable constructed: ammap/callables/multi_system_equilibrium_and_scheil/scheil_callable_NiTiV_1d83c99c.py\n"
     ]
    }
   ],
   "source": [
    "# Create thermodynamic callables\n",
    "!python ammap/callableBuilders/construct_callables.py {yaml_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "nDivisionsPerDimension\n",
      "elementalSpaces\n",
      "designSpaces\n",
      "constraints\n",
      "pathPlan\n"
     ]
    }
   ],
   "source": [
    "for key in yaml_content.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name', 'nDivisionsPerDimension', 'elementalSpaces', 'designSpaces', 'constraints', 'pathPlan'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['type', 'temperature', 'pressure', 'feasiblePhases'])\n"
     ]
    }
   ],
   "source": [
    "print(yaml_content.keys())\n",
    "print(type(yaml_content['elementalSpaces']))\n",
    "print(type(yaml_content['elementalSpaces'][0]))\n",
    "print(type(yaml_content['constraints']))\n",
    "print(type(yaml_content['constraints'][0]))\n",
    "print(yaml_content['constraints'][0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cr', 'Fe', 'Ni', 'Ti', 'V']\n"
     ]
    }
   ],
   "source": [
    "#Reads all elements from the elementalSpaces (base elements)\n",
    "elementalSpaceComponents = sorted(list({elem for element in yaml_content['elementalSpaces'] for elem in element['elements']}))\n",
    "print(elementalSpaceComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible entry options in design_spaces:\n",
      "['name', 'elementalSpace', 'components']\n",
      "['stitch', 'targetDesignSpace']\n",
      "['stitch', 'targetDesignSpace']\n",
      "['stitch', 'targetDesignSpace']\n",
      "['name', 'elementalSpace', 'components']\n",
      "['name', 'elementalSpace', 'components']\n",
      "['name', 'elementalSpace', 'components']\n",
      "['name', 'elementalSpace', 'components']\n",
      "['name', 'elementalSpace', 'components']\n",
      "['name', 'elementalSpace', 'components']\n",
      "['name', 'elementalSpace', 'components']\n",
      "['name', 'elementalSpace', 'components']\n",
      "['name', 'elementalSpace', 'components']\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible entry options in design_spaces:\")\n",
    "for entry in design_spaces:\n",
    "    print(list(entry.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cr', 'Fe', 'Ni', 'Ti', 'V']\n"
     ]
    }
   ],
   "source": [
    "#Make this come from YAML (designSpaces)\n",
    "design_spaces = yaml_content['designSpaces']\n",
    "# Combine all the names of each entry in designSpaces\n",
    "attainableSpaceComponents = []\n",
    "for entry in design_spaces:\n",
    "    if 'name' in entry:\n",
    "        components = re.findall(r'[A-Z][a-z]*', entry['name'])\n",
    "        attainableSpaceComponents.extend(components)\n",
    "\n",
    "# Remove duplicates and sort the list\n",
    "attainableSpaceComponents = sorted(set(attainableSpaceComponents))\n",
    "\n",
    "\n",
    "print(attainableSpaceComponents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attainable Space Components:\n",
      "['Cr', 'Ni', 'Ss', 'Ti', 'V']\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import re\n",
    "\n",
    "# Load the YAML file\n",
    "with open('example_input.yaml', 'r') as file:\n",
    "    yaml_content = yaml.safe_load(file)\n",
    "\n",
    "# Extract the designSpaces key\n",
    "design_spaces = yaml_content['designSpaces']\n",
    "\n",
    "# Combine all the names of each entry in designSpaces\n",
    "attainableSpaceComponents = []\n",
    "for entry in design_spaces:\n",
    "    components = re.findall(r'[A-Z][a-z]*', entry['name'])\n",
    "    attainableSpaceComponents.extend(components)\n",
    "\n",
    "# Remove duplicates and sort the list\n",
    "attainableSpaceComponents = sorted(set(attainableSpaceComponents))\n",
    "\n",
    "# Print the results for verification\n",
    "print(\"Attainable Space Components:\")\n",
    "print(attainableSpaceComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attainable Space Components:\n",
      "['Cr', 'Ni', 'Ss', 'Ti', 'V']\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import re\n",
    "\n",
    "# Load the YAML file\n",
    "with open('example_input.yaml', 'r') as file:\n",
    "    yaml_content = yaml.safe_load(file)\n",
    "\n",
    "# Extract the designSpaces key\n",
    "design_spaces = yaml_content['designSpaces']\n",
    "\n",
    "# Combine all the names of each entry in designSpaces\n",
    "attainableSpaceComponents = []\n",
    "for entry in design_spaces:\n",
    "    components = re.findall(r'[A-Z][a-z]*', entry['name'])\n",
    "    attainableSpaceComponents.extend(components)\n",
    "\n",
    "# Remove duplicates and sort the list\n",
    "attainableSpaceComponents = sorted(set(attainableSpaceComponents))\n",
    "\n",
    "# Print the results for verification\n",
    "print(\"Attainable Space Components:\")\n",
    "print(attainableSpaceComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make this come from YAML (designSpaces)\n",
    "#Reads the desired components for the design space that may not be constrained to base elements\n",
    "attainableSpaceComponents = [\"Cr\", \"Fe\", \"Ni\", \"Ti\", \"V\"]\n",
    "attainableSpaceComponentPositions = [\n",
    "    [1,0,0,0,0],\n",
    "    [0,1,0,0,0],\n",
    "    [0,0,1,0,0],\n",
    "    [0,0,0,1,0],\n",
    "    [0,0,0,0,1]\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cr', 'Fe', 'Ni')                       -> ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0])\n",
      "('Cr', 'Fe', 'Ti')                       -> ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0])\n",
      "('Cr', 'Fe', 'V')                        -> ([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 1])\n",
      "('Cr', 'Ni', 'Ti')                       -> ([1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0])\n",
      "('Cr', 'Ni', 'V')                        -> ([1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1])\n",
      "('Cr', 'Ti', 'V')                        -> ([1, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n",
      "('Fe', 'Ni', 'Ti')                       -> ([0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0])\n",
      "('Fe', 'Ni', 'V')                        -> ([0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1])\n",
      "('Fe', 'Ti', 'V')                        -> ([0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n",
      "('Ni', 'Ti', 'V')                        -> ([0, 0, 1, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "ternaries = list(combinations(attainableSpaceComponents, 3))\n",
    "ternaries_CompPos = list(combinations(attainableSpaceComponentPositions, 3))\n",
    "ndiv = yaml_content['nDivisionsPerDimension']\n",
    "gridAtt, nList = nimplex.simplex_graph_py(3, ndiv)\n",
    "\n",
    "for tern, terncp in zip(ternaries, ternaries_CompPos):\n",
    "    print(f\"{str(tern):<40} -> {terncp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 1, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(terncp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0])\n",
      "([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0])\n",
      "([1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 1])\n",
      "([1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0])\n",
      "([1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1])\n",
      "([1, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n",
      "([0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0])\n",
      "([0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 1])\n",
      "([0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n",
      "([0, 0, 1, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "# Edges list for graph plotting and path finding purposes\n",
    "edges = []\n",
    "# Connectivity list within each subsystem\n",
    "graphN = [[] for i in range(len(gridAtt * len(ternaries)))]\n",
    "# Connectivity list between subsystems\n",
    "graphNS = [[] for i in range(len(graphN))]\n",
    "compositions = []\n",
    "compositions_with_id = []  # List to store compositions with their identifiers\n",
    "ternaries_with_id = []  # New list to store ternaries_CompPos with their identifiers\n",
    "\n",
    "# Iterate over ternaries\n",
    "for i, terncp in enumerate(ternaries_CompPos):\n",
    "    ternaries_with_id.append((terncp, i))  # Add terncp and its id to the new list\n",
    "    \n",
    "    offset = i*len(gridAtt)\n",
    "    for j in range(len(gridAtt)):\n",
    "        for n in nList[j]:\n",
    "            edges.append((j+offset,n+offset))\n",
    "            graphN[j+offset].append(n+offset)\n",
    "    print(terncp)\n",
    "    gridAttTemp, gridElTemp = nimplex.embeddedpair_simplex_grid_fractional_py(terncp, ndiv)\n",
    "    compositions += gridElTemp\n",
    "    \n",
    "    # Attach identifier to each composition\n",
    "    compositions_with_id.extend([(comp, i) for comp in gridElTemp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination: CrFeNi, ID: 0, Elements: ['Cr', 'Fe', 'Ni']\n",
      "Combination: CrFeTi, ID: 1, Elements: ['Cr', 'Fe', 'Ti']\n",
      "Combination: CrFeV, ID: 2, Elements: ['Cr', 'Fe', 'V']\n",
      "Combination: CrNiTi, ID: 3, Elements: ['Cr', 'Ni', 'Ti']\n",
      "Combination: CrNiV, ID: 4, Elements: ['Cr', 'Ni', 'V']\n",
      "Combination: CrTiV, ID: 5, Elements: ['Cr', 'Ti', 'V']\n",
      "Combination: FeNiTi, ID: 6, Elements: ['Fe', 'Ni', 'Ti']\n",
      "Combination: FeNiV, ID: 7, Elements: ['Fe', 'Ni', 'V']\n",
      "Combination: FeTiV, ID: 8, Elements: ['Fe', 'Ti', 'V']\n",
      "Combination: NiTiV, ID: 9, Elements: ['Ni', 'Ti', 'V']\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for ternary, id in ternaries_with_id:\n",
    "    composition_key = ''.join(elementalSpaceComponents[i] for i in range(len(elementalSpaceComponents)) if any(ternary[j][i] for j in range(len(ternary))))\n",
    "    individual_elements = [elementalSpaceComponents[i] for i in range(len(elementalSpaceComponents)) if any(ternary[j][i] for j in range(len(ternary)))]\n",
    "    mapping[composition_key] = {\n",
    "        'id': id,\n",
    "        'elements': individual_elements\n",
    "    }\n",
    "\n",
    "# Print the mapping to see the result\n",
    "for key, value in mapping.items():\n",
    "    print(f\"Combination: {key}, ID: {value['id']}, Elements: {value['elements']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchingBinaries = {}\n",
    "\n",
    "for i, combo1 in enumerate(ternaries):\n",
    "    for j, combo2 in enumerate(ternaries[i+1:], start=i+1):\n",
    "        common = set(combo1) & set(combo2)\n",
    "        if len(common) == 2:\n",
    "            overlap = tuple(sorted(common))\n",
    "            if overlap not in stitchingBinaries:\n",
    "                stitchingBinaries[overlap] = []\n",
    "            stitchingBinaries[overlap].append((i, j))\n",
    "\n",
    "for overlap, pairs in stitchingBinaries.items():\n",
    "    print(f\"{overlap}: occurs between ternary {pairs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stitchingBinary, ternaryPairList in stitchingBinaries.items():\n",
    "    for ternaryPair in ternaryPairList:\n",
    "        ternary1, ternary2 = ternaryPair[0], ternaryPair[1]\n",
    "        stitching1 = stitching.findStitchingPoints_py(\n",
    "            3, ndiv, \n",
    "            components=ternaries[ternary1],\n",
    "            offset=ternary1*len(gridAtt)\n",
    "            )[\"-\".join(stitchingBinary)]\n",
    "        stitching2 = stitching.findStitchingPoints_py(\n",
    "            3, ndiv, \n",
    "            components=ternaries[ternary2],\n",
    "            offset=ternary2*len(gridAtt)\n",
    "            )[\"-\".join(stitchingBinary)]\n",
    "        print(f\"Stitching {ternary1} and {ternary2} at {stitchingBinary} from {stitching1} to {stitching2}\")\n",
    "        for i, j in zip(stitching1, stitching2):\n",
    "            #To\n",
    "            edges.append((i, j))\n",
    "            graphNS[i].append(j)\n",
    "            #From\n",
    "            edges.append((j, i))\n",
    "            graphNS[j].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_files = [\n",
    "    \"ammap/databases/Co-Cr-Fe-Ni-V_choi2019.TDB\",\n",
    "    \"ammap/databases/Cr-Fe-Ti_wang2017.tdb\",\n",
    "    \"ammap/databases/Cr-Fe-Ni_miettinen1999.tdb\",\n",
    "    \"ammap/databases/Cr-Ni-Ti_huang2018.tdb\",\n",
    "    \"ammap/databases/Cr-Ti-V_ghosh2002.tdb\",\n",
    "    \"ammap/databases/Fe-Ni-Ti_dekeyzer2009.tdb\",\n",
    "    \"ammap/databases/Fe-Ni-V_zhao2014.tdb\",\n",
    "    \"ammap/databases/Fe-Ti-V_guo2012.TDB\",\n",
    "    \"ammap/databases/Ni-Ti-V_zou2018.tdb\"\n",
    "]\n",
    "\n",
    "# Dictionary to store unique phases for each database\n",
    "unique_phases = {}\n",
    "\n",
    "# Iterate through each database file\n",
    "for db_file in db_files:\n",
    "    dbf = Database(db_file)\n",
    "    phases = list(set(dbf.phases.keys()))\n",
    "    unique_phases[db_file] = phases\n",
    "\n",
    "# Print unique phases for each database\n",
    "for db_file, phases in unique_phases.items():\n",
    "    print(f\"Unique phases for {db_file}: {phases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = list(set(dbf.phases.keys()))\n",
    "print(elementalSpaceComponents)\n",
    "print(f'Loaded TDB file with phases considered: {phases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the equilibrium files\n",
    "directory = \"ammap/callables/multi_system_equilibrium_and_scheil\"\n",
    "\n",
    "# Get all files starting with \"equilibrium\"\n",
    "equilibrium_files = [f for f in os.listdir(directory) if f.startswith(\"equilibrium\") and f.endswith(\".py\")]\n",
    "\n",
    "# Dictionary to store imported callables with unique names\n",
    "equilibrium_callables = {}\n",
    "\n",
    "# Import each equilibrium file and store the callable with a unique name\n",
    "for file in equilibrium_files:\n",
    "    module_name = file[:-3]  # Remove the .py extension\n",
    "    module_path = f\"ammap.callables.multi_system_equilibrium_and_scheil.{module_name}\"\n",
    "    module = importlib.import_module(module_path)\n",
    "    callable_name = f\"{module_name}\"\n",
    "    equilibrium_callables[callable_name] = getattr(module, \"equilibrium_callable\")\n",
    "\n",
    "# Print the imported callables\n",
    "for name, func in equilibrium_callables.items():\n",
    "    print(f\"Imported {name}: {func}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheil_files = [f for f in os.listdir(directory) if f.startswith(\"scheil\") and f.endswith(\".py\")]\n",
    "scheil_callables = {}\n",
    "\n",
    "for file in scheil_files:\n",
    "    module_name = file[:-3]\n",
    "    module_path = f\"ammap.callables.multi_system_equilibrium_and_scheil.{module_name}\"\n",
    "    module = importlib.import_module(module_path)\n",
    "    callable_name = f\"{module_name}\"\n",
    "    scheil_callables[callable_name] = getattr(module, \"scheil_callable\")\n",
    "\n",
    "for name, func in scheil_callables.items():\n",
    "    print(f\"Imported {name}: {func}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        middle_part = parts[2]\n",
    "        if middle_part in element_mapping:\n",
    "            return middle_part, element_mapping[middle_part]\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_key(key):\n",
    "    parts = key.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        middle_part = parts[2]\n",
    "        if middle_part in mapping:\n",
    "            return middle_part, mapping[middle_part]['id'], mapping[middle_part]['elements']\n",
    "        \n",
    "        # If direct matching fails, try matching by elements\n",
    "        middle_elements = set(middle_part[i:i+2] for i in range(0, len(middle_part), 2))\n",
    "        for map_key, value in mapping.items():\n",
    "            if set(value['elements']) == middle_elements:\n",
    "                return middle_part, value['id'], value['elements']\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "# Process each key in the equilibrium_callables dictionary\n",
    "id_to_callable = {}\n",
    "for key in equilibrium_callables:\n",
    "    middle_part, mapping_id, elements = process_key(key)\n",
    "    if middle_part and mapping_id is not None:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"The mapping number for {middle_part} is {mapping_id}\")\n",
    "        print(f\"Elements: {elements}\")\n",
    "        print(\"---\")\n",
    "        id_to_callable[mapping_id] = key\n",
    "    else:\n",
    "        print(f\"No mapping found for key: {key}\")\n",
    "        print(\"---\")\n",
    "\n",
    "sc_id_to_callable = {}\n",
    "for key in scheil_callables:\n",
    "    middle_part, mapping_id, elements = process_key(key)\n",
    "    if middle_part and mapping_id is not None:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"The mapping number for {middle_part} is {mapping_id}\")\n",
    "        print(f\"Elements: {elements}\")\n",
    "        print(\"---\")\n",
    "        sc_id_to_callable[mapping_id] = key\n",
    "    else:\n",
    "        print(f\"No mapping found for key: {key}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_compositions(compositions_with_id, mapping):\n",
    "    element_order = elementalSpaceComponents\n",
    "    system_comps_with_id = []\n",
    "    reduced_compositions = []\n",
    "    \n",
    "    for composition, comp_id in compositions_with_id:\n",
    "        relevant_entry = next((entry for entry in mapping.values() if entry['id'] == comp_id), None)\n",
    "        if not relevant_entry:\n",
    "            continue\n",
    "        \n",
    "        relevant_indices = [element_order.index(elem) for elem in relevant_entry['elements']]\n",
    "        reduced_point = [composition[index] for index in relevant_indices]\n",
    "        system_comps_with_id.append((reduced_point, comp_id))\n",
    "        reduced_compositions.append(reduced_point)\n",
    "    \n",
    "    return system_comps_with_id, reduced_compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_comps_with_id, reduced_compositions = reduce_compositions(compositions_with_id, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startingNodes = [0, 90, 20, 31] + random.sample(range(len(reduced_compositions)), 11)\n",
    "print(f\"Starting nodes: {startingNodes}\")\n",
    "\n",
    "for startingNode in startingNodes:\n",
    "    print(f\"Starting node: {reduced_compositions[startingNode]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridFeasible = [None]*len(reduced_compositions)\n",
    "queue = startingNodes.copy()\n",
    "explored = set()\n",
    "calcCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the correct callable for a given composition\n",
    "def get_callable(composition):\n",
    "    for comp, id in compositions_with_id:\n",
    "        if comp == composition:\n",
    "            callable_name = id_to_callable.get(id)\n",
    "            if callable_name is None:\n",
    "                raise ValueError(f\"No callable name found for ID {id}\")\n",
    "            if callable_name in globals():\n",
    "                return globals()[callable_name]\n",
    "            else:\n",
    "                raise NameError(f\"Function '{callable_name}' not found in global scope\")\n",
    "    raise ValueError(f\"No callable found for composition {composition}\")\n",
    "\n",
    "def process_composition(elP):\n",
    "    try:\n",
    "        callable_func = get_callable(elP)\n",
    "        return callable_func(elP)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing composition {elP}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the correct callable for a given composition\n",
    "def get_sc_callable(composition):\n",
    "    for comp, id in compositions_with_id:\n",
    "        if comp == composition:\n",
    "            callable_name = sc_id_to_callable.get(id)\n",
    "            if callable_name is None:\n",
    "                raise ValueError(f\"No callable name found for ID {id}\")\n",
    "            if callable_name in globals():\n",
    "                return globals()[callable_name]\n",
    "            else:\n",
    "                raise NameError(f\"Function '{callable_name}' not found in global scope\")\n",
    "    raise ValueError(f\"No callable found for composition {composition}\")\n",
    "\n",
    "def process_sc_composition(elP):\n",
    "    try:\n",
    "        callable_func = get_sc_callable(elP)\n",
    "        return callable_func(elP)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing composition {elP}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def get_equilibrium_callable(composition, id_to_callable, equilibrium_callables):\n",
    "    composition_id = composition[1]  # Get the ID from the composition tuple\n",
    "    #print(f\"Composition ID: {composition_id}\")\n",
    "    callable_name = id_to_callable.get(composition_id)\n",
    "    if callable_name is None:\n",
    "        raise ValueError(f\"No callable found for composition ID {composition_id}\")\n",
    "    callable_func = equilibrium_callables.get(callable_name)\n",
    "    if callable_func is None:\n",
    "        raise ValueError(f\"No callable function found for name {callable_name}\")\n",
    "    return callable_func\n",
    "\n",
    "def apply_equilibrium_callable(callable_and_position):\n",
    "    callable_func, position = callable_and_position\n",
    "    return callable_func(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheil_callable(composition, sc_id_to_callable, scheil_callables):\n",
    "    composition_id = composition[1]  # Get the ID from the composition tuple\n",
    "    #print(f\"Composition ID: {composition_id}\")\n",
    "    callable_name = sc_id_to_callable.get(composition_id)\n",
    "    if callable_name is None:\n",
    "        raise ValueError(f\"No callable found for composition ID {composition_id}\")\n",
    "    callable_func = scheil_callables.get(callable_name)\n",
    "    if callable_func is None:\n",
    "        raise ValueError(f\"No callable function found for name {callable_name}\")\n",
    "    return callable_func\n",
    "\n",
    "def apply_scheil_callable(callable_and_position):\n",
    "    callable_func, position = callable_and_position\n",
    "    return callable_func(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "while len(queue) > 0:\n",
    "    print(f\"Queue: {queue}\")\n",
    "    # Calculate feasibilities of the current queue\n",
    "    elPositions = [reduced_compositions[i] for i in queue]\n",
    "    print(elPositions)\n",
    "    # Create a list of equilibrium callables for each composition\n",
    "    equilibrium_callables_list = [get_equilibrium_callable(system_comps_with_id[i], id_to_callable, equilibrium_callables) for i in queue]\n",
    "    \n",
    "    if len(queue) > 3:\n",
    "        results = process_map(apply_equilibrium_callable, zip(equilibrium_callables_list, elPositions), max_workers=4)\n",
    "    else:\n",
    "        results = [ec(elP) for ec, elP in zip(equilibrium_callables_list, elPositions)]\n",
    "    \n",
    "    # Extract only the 'Phases' component from the results\n",
    "    phases = [result['Phases'] for result in results]\n",
    "    \n",
    "    #feasibilities = [len(set(p) & set(['FCC_A1', 'BCC_A2', 'HCP_A3', 'B2_BCC','A2_FCC','L12_FCC','BCC2', 'A1', 'A2', 'A3', 'FCC4'])) == 0 and p != [] for p in phases]\n",
    "    feasibilities = [set(p).issubset(set(['FCC_A1', 'BCC_A2', 'HCP_A3', 'B2_BCC', 'A2_FCC', 'L12_FCC', 'BCC2', 'A1', 'A2', 'A3', 'FCC4'])) and p != [] for p in phases]\n",
    "\n",
    "    calcCount += len(feasibilities)\n",
    "    explored = explored.union(queue)\n",
    "\n",
    "    # Save the current step result and elPositions\n",
    "    results_list.append({\n",
    "        'queue': queue,\n",
    "        'elPositions': elPositions,\n",
    "        'results': results\n",
    "    })\n",
    "\n",
    "    # Create next queue based on neighbors of feasible points\n",
    "    nextQueue = set()\n",
    "    #nextQueuePlusEquivalent = set()\n",
    "    for f, i in zip(feasibilities, queue):\n",
    "        # Explored point\n",
    "        gridFeasible[i] = f\n",
    "\n",
    "        # # And equivalent explored points based on system stitching\n",
    "        # explored = explored.union(graphNS[i])\n",
    "        # for eq in graphNS[i]:\n",
    "        #     gridFeasible[eq] = f\n",
    "\n",
    "        # Expand to neighbors of the point and equivalent points (only if the node has been feasible)\n",
    "        if f:\n",
    "            # Node neighbors in the same subsystem\n",
    "            for n in graphN[i]:\n",
    "                if n not in explored:# and n not in nextQueuePlusEquivalent:\n",
    "                    nextQueue.add(n)\n",
    "                    #nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "            # Equivalent nodes neighbors in other subsystems\n",
    "            for eq in graphNS[i]:\n",
    "                #for n in graphN[eq]:\n",
    "                if eq not in explored:# and n not in nextQueuePlusEquivalent:\n",
    "                    nextQueue.add(eq)\n",
    "                    #nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "\n",
    "    print(f\"Calculations done: {calcCount:<5} | Explored points: {len(explored):<5}\")\n",
    "    queue = list(nextQueue)\n",
    "\n",
    "# Write the results to a JSON file\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the JSON file\n",
    "with open('/ocean/projects/dmr190011p/arichte1/github_repo/AMMap/results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the merged results\n",
    "merged_results = {}\n",
    "\n",
    "# Iterate through each step in the data\n",
    "for step in data:\n",
    "    queue = step['queue']\n",
    "    results = step['results']\n",
    "    \n",
    "    # Merge the queue numbers with their associated result values\n",
    "    for q, result in zip(queue, results):\n",
    "        merged_results[q] = result\n",
    "\n",
    "# Convert the merged results dictionary to a list of dictionaries\n",
    "merged_results_list = [{'queue': q, 'result': result} for q, result in merged_results.items()]\n",
    "\n",
    "# Save the merged results to a new JSON file\n",
    "with open('merged_results.json', 'w') as f:\n",
    "    json.dump(merged_results_list, f, indent=4)\n",
    "with open('grid_feasible.json', 'w') as f:\n",
    "    json.dump(gridFeasible, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridFeasible1 = [None]*len(reduced_compositions)\n",
    "queue = startingNodes.copy()\n",
    "explored = set()\n",
    "calcCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def apply_scheil_callable(args):\n",
    "    sc, elP = args\n",
    "    try:\n",
    "        return sc(elP)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing item: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_list = []\n",
    "\n",
    "while len(queue) > 0:\n",
    "    print(f\"Queue: {queue}\")\n",
    "    # Calculate feasibilities of the current queue\n",
    "    elPositions = [reduced_compositions[i] for i in queue]\n",
    "    print(elPositions)\n",
    "    # Create a list of scheil callables for each composition\n",
    "    scheil_callables_list = [get_scheil_callable(system_comps_with_id[i], sc_id_to_callable, scheil_callables) for i in queue]\n",
    "    \n",
    "    if len(queue) > 3:\n",
    "        results = process_map(apply_scheil_callable, zip(scheil_callables_list, elPositions), max_workers=4)\n",
    "    else:\n",
    "        results = [apply_scheil_callable((sc, elP)) for sc, elP in zip(scheil_callables_list, elPositions)]\n",
    "    \n",
    "    # Filter out None values (errors) and process valid results\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "    \n",
    "    # Extract only the 'Phases' component from the valid results\n",
    "    phases = [result['finalPhase'] for result in valid_results]\n",
    "    \n",
    "    feasibilities = [set(p).issubset(set(['FCC_A1', 'BCC_A2', 'HCP_A3', 'B2_BCC', 'A2_FCC', 'L12_FCC', 'BCC2', 'A1', 'A2', 'A3', 'FCC4'])) and p != [] for p in phases]\n",
    "\n",
    "    calcCount += len(feasibilities)\n",
    "    explored = explored.union(queue)\n",
    "\n",
    "    # Save the current step result and elPositions\n",
    "    results_list.append({\n",
    "        'queue': queue,\n",
    "        'elPositions': elPositions,\n",
    "        'results': valid_results\n",
    "    })\n",
    "\n",
    "    \n",
    "    # Create next queue based on neighbors of feasible points\n",
    "    nextQueue = set()\n",
    "    #nextQueuePlusEquivalent = set()\n",
    "    for f, i in zip(feasibilities, queue):\n",
    "        # Explored point\n",
    "        gridFeasible[i] = f\n",
    "\n",
    "        # # And equivalent explored points based on system stitching\n",
    "        # explored = explored.union(graphNS[i])\n",
    "        # for eq in graphNS[i]:\n",
    "        #     gridFeasible[eq] = f\n",
    "\n",
    "        # Expand to neighbors of the point and equivalent points (only if the node has been feasible)\n",
    "        if f:\n",
    "            # Node neighbors in the same subsystem\n",
    "            for n in graphN[i]:\n",
    "                if n not in explored:# and n not in nextQueuePlusEquivalent:\n",
    "                    nextQueue.add(n)\n",
    "                    #nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "            # Equivalent nodes neighbors in other subsystems\n",
    "            for eq in graphNS[i]:\n",
    "                #for n in graphN[eq]:\n",
    "                if eq not in explored:# and n not in nextQueuePlusEquivalent:\n",
    "                    nextQueue.add(eq)\n",
    "                    #nextQueuePlusEquivalent = nextQueuePlusEquivalent.union([n] + graphNS[n])\n",
    "\n",
    "    print(f\"Calculations done: {calcCount:<5} | Explored points: {len(explored):<5}\")\n",
    "    queue = list(nextQueue)\n",
    "\n",
    "# Write the results to a JSON file\n",
    "with open('scheil_results.json', 'w') as f:\n",
    "    json.dump(results_list, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the results from the JSON file\n",
    "with open('/ocean/projects/dmr190011p/arichte1/github_repo/AMMap/scheil_results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the merged results\n",
    "merged_results = {}\n",
    "\n",
    "# Iterate through each step in the data\n",
    "for step in data:\n",
    "    queue = step['queue']\n",
    "    results = step['results']\n",
    "    \n",
    "    # Merge the queue numbers with their associated result values\n",
    "    for q, result in zip(queue, results):\n",
    "        merged_results[q] = result\n",
    "\n",
    "# Convert the merged results dictionary to a list of dictionaries\n",
    "merged_results_list = [{'queue': q, 'result': result} for q, result in merged_results.items()]\n",
    "\n",
    "# Save the merged results to a new JSON file\n",
    "with open('merged_scheil_results.json', 'w') as f:\n",
    "    json.dump(merged_results_list, f, indent=4)\n",
    "with open('grid_feasible1.json', 'w') as f:\n",
    "    json.dump(gridFeasible1, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathfinding.core.graph import Graph\n",
    "from pathfinding.finder.dijkstra import DijkstraFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "with open('grid_feasible.json', 'r') as f:\n",
    "    gridFeasible = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edges.json', 'w') as file:\n",
    "    json.dump(edges, file)\n",
    "with open('graphNS.json', 'w') as file:\n",
    "    json.dump(graphNS, file)\n",
    "with open('graphN.json', 'w') as file:\n",
    "    json.dump(graphN, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFindEdges = []\n",
    "for edge in edges:\n",
    "    if gridFeasible[edge[0]] and gridFeasible[edge[1]]:\n",
    "        pathFindEdges.append([edge[0], edge[1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathfindingGraph = Graph(edges=pathFindEdges, bi_directional=False)\n",
    "finder = DijkstraFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YAML file inputs needed here\n",
    "startingComposition=[0.18, 0.74, 0.08, 0.0, 0.0]\n",
    "endingComposition=[0.0, 0.0, 0.0, 0.95, 0.05]\n",
    "gridElArray = np.array(compositions)\n",
    "# Find the position of startingComposition\n",
    "startingCompositionArray = np.array(startingComposition)\n",
    "endingCompositionArray = np.array(endingComposition)\n",
    "print(f\"Looking for: {startingCompositionArray}\")\n",
    "print(f\"Looking for: {endingCompositionArray}\")\n",
    "# New code, looking for the closest match\n",
    "startingCompositionPosition = np.argmin(np.sum(np.abs(gridElArray - startingCompositionArray), axis=1))\n",
    "endingCompositionPosition = np.argmin(np.sum(np.abs(gridElArray - endingCompositionArray), axis=1))\n",
    "print(f\"\\nNode: {startingCompositionPosition} --> {gridElArray[startingCompositionPosition]}\")\n",
    "print(f\"Node: {endingCompositionPosition} --> {gridElArray[endingCompositionPosition]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_node_id = 194\n",
    "# end_node_id = 830\n",
    "start_node_id = startingCompositionPosition#12\n",
    "end_node_id = endingCompositionPosition\n",
    "\n",
    "# Check if the nodes exist in the graph\n",
    "if start_node_id in pathfindingGraph.nodes and end_node_id in pathfindingGraph.nodes:\n",
    "    path, runs = finder.find_path(\n",
    "        pathfindingGraph.node(start_node_id), \n",
    "        pathfindingGraph.node(end_node_id), \n",
    "        pathfindingGraph)\n",
    "    print(\"Path found:\", path)\n",
    "else:\n",
    "    print(f\"One or both of the nodes {start_node_id} and {end_node_id} do not exist in the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortestPath = [p.node_id for p in path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hover approximate formula for each point\n",
    "formulas = []\n",
    "for i, comp in enumerate(compositions):\n",
    "    formulas.append(f\"({i:>3}) \"+\"\".join([f\"{el}{100*v:.1f} \" if v>0 else \"\" for el, v in zip(elementalSpaceComponents, comp)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, i in enumerate(shortestPath):\n",
    "    print(f\"{step+1:>2}: {formulas[i]}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shortestPath_eq.json', 'w') as file:\n",
    "    json.dump(shortestPath, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
